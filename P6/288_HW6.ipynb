{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "288_HW6",
      "provenance": [],
      "collapsed_sections": [
        "SdrBPH9dnatJ",
        "Ar8IvqsRnatK",
        "RFYuH6SwnatP",
        "mFWKBO5BnatR",
        "T3DKnL4HnatT",
        "9DsKanTTnatU"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Grounding and Pragmatics\n",
        "\n",
        "The final homework for Berkeley CS288 will cover language grounding and pragmatics. We'll focus on a simple reference game domain known as [Colors in Context](https://arxiv.org/abs/1703.10186). Clasically, reference games involve two players, a speaker and a listener. Both players see a shared set of *referents* and the speaker is given a target reference which they must describe to the listener in the presence of distractors. For example, consider the image captioning task below, taken from the paper [Reasoning about Pragmatics with Neural Listeners and Speakers](https://aclanthology.org/D16-1125.pdf) by Jacob Andreas and Dan Klein:\n",
        "\n",
        "![Screen Shot 2022-04-29 at 10.21.47 PM.png](attachment:ac932fdb-ca78-49aa-8f74-ca0d3da5add8.png)\n",
        "\n",
        "We'll focus on a much simpler reference game in which images are replaced with colors. Your task will be to build a language generation model (speaker) which describes a color in the context of distractor colors, as well as a language understanding model (listener) which predicts a color given an utterance. The vast majority of the stencil code is provided for you in this homework.\n",
        "\n",
        "Code from this notebook is attributable to Stanford CS224U, taught by Christopher Potts."
      ],
      "metadata": {
        "id": "J7T_pEIvnatA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "V32NVf4rzkVB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cmath\n",
        "import colorsys\n",
        "import copy\n",
        "import csv\n",
        "import itertools\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatch\n",
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import sys\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "from itertools import product\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer \n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, train_test_split"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:23.583417Z",
          "iopub.execute_input": "2022-04-30T09:15:23.583713Z",
          "iopub.status.idle": "2022-04-30T09:15:23.591126Z",
          "shell.execute_reply.started": "2022-04-30T09:15:23.583665Z",
          "shell.execute_reply": "2022-04-30T09:15:23.590359Z"
        },
        "trusted": true,
        "id": "YR9nelvwnatD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "metadata": {
        "id": "Jfpq5GuNrS2c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: Colors in Context\n",
        "\n",
        "[Colors in Context](https://arxiv.org/abs/1703.10186) is a reference game dataset developed by Will Monroe, Robert XD Hawkins, Noah Goodman, and Christopher Potts. It contains color swatches paired with English language annotations for a target swatch, although [supplementary data in Mandarin also exists](https://aclanthology.org/N18-1196.pdf). In this notebook, we'll focus only on a subset of the English data. The following code is used for visualizing sample data and can be safely ignored:"
      ],
      "metadata": {
        "id": "-WGCwebFnatE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TURN_BOUNDARY =  \" ### \"\n",
        "\n",
        "class ColorsCorpusReader:\n",
        "    \"\"\"\n",
        "    Basic interface for the Stanford Colors in Context corpus:\n",
        "    https://cocolab.stanford.edu/datasets/colors.html\n",
        "    Parameters\n",
        "    ----------\n",
        "    src_filename : str\n",
        "        Full path to the corpus file.\n",
        "    word_count : int or None\n",
        "        If int, then only examples with `word_count` words in their\n",
        "        'contents' field are included (as estimated by the number of\n",
        "        whitespqce tokens). If None, then all examples are returned.\n",
        "    normalize_colors : bool\n",
        "         The colors in the corpus are in HLS format with values\n",
        "         [0, 360], [0, 100], [0, 100]. If `normalize_colors=True`,\n",
        "         these are scaled into [0, 1], [0, 1], [0, 1].\n",
        "    Usage\n",
        "    -----\n",
        "    corpus = ColorsCorpusReader('filteredCorpus.csv')\n",
        "    for ex in corpus.read():\n",
        "        # ...\n",
        "    \"\"\"\n",
        "    def __init__(self, src_filename, word_count=None, normalize_colors=True):\n",
        "        self.src_filename = src_filename\n",
        "        self.word_count = word_count\n",
        "        self.normalize_colors = normalize_colors\n",
        "\n",
        "    def read(self):\n",
        "        \"\"\"\n",
        "        The main interface to the corpus.\n",
        "        As in the paper, turns taken in the same game and round are\n",
        "        grouped together into a single `ColorsCorpusExample` instance\n",
        "        with the turn texts separated by `TURN_BOUNDARY`, formatted\n",
        "        as a string.\n",
        "        Yields\n",
        "        ------\n",
        "        `ColorsCorpusExample` with the `normalize_colors` attribute set\n",
        "        as in `self.normalize_colors` in this class.\n",
        "        \"\"\"\n",
        "        grouped = defaultdict(list)\n",
        "        with open(self.src_filename) as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for row in reader:\n",
        "                if row['role'] == 'speaker' and self._word_count_filter(row):\n",
        "                    grouped[(row['gameid'], row['roundNum'])].append(row)\n",
        "        for rows in grouped.values():\n",
        "            yield ColorsCorpusExample(\n",
        "                rows, normalize_colors=self.normalize_colors)\n",
        "\n",
        "    def _word_count_filter(self, row):\n",
        "        return self.word_count is None or \\\n",
        "          row['contents'].count(\" \") == (self.word_count-1)\n",
        "\n",
        "\n",
        "class ColorsCorpusExample:\n",
        "    \"\"\"\n",
        "    Interface to individual examples in the Stanford Colors in\n",
        "    Context corpus.\n",
        "    Parameters\n",
        "    ----------\n",
        "    rows : list of dict\n",
        "        This contains all of the turns associated with a given game\n",
        "        and round. The assumption is that all of the key-value pairs\n",
        "        in these dicts are the same except for the 'contents' key.\n",
        "    normalize_colors : bool\n",
        "         The colors in the corpus are in HLS format with values\n",
        "         [0, 360], [0, 100], [0, 100]. If `normalize_colors=True`,\n",
        "         these are scaled into [0, 1], [0, 1], [0, 1].\n",
        "    Usage\n",
        "    -----\n",
        "    We assume that these instances are created by `ColorsCorpusReader`.\n",
        "    For an example of one being created directly, see\n",
        "    `test/test_colors.py::test_color_corpus_example`.\n",
        "    Note\n",
        "    ----\n",
        "    There are values in the corpus that are present in `rows` but\n",
        "    not captured in attributes right now, to keep this code from\n",
        "    growing very complex. It should be straightforward to bring\n",
        "    in these additional attributes by subclassing this class.\n",
        "    \"\"\"\n",
        "    def __init__(self, rows, normalize_colors=True):\n",
        "        self.normalize_colors = normalize_colors\n",
        "        self.contents = TURN_BOUNDARY.join([r['contents'] for r in rows])\n",
        "        # Make sure our assumptions about these rows are correct:\n",
        "        self._check_row_alignment(rows)\n",
        "        row = rows[0]\n",
        "        self.gameid = row['gameid']\n",
        "        self.roundNum = int(row['roundNum'])\n",
        "        self.condition = row['condition']\n",
        "        self.outcome = row['outcome'] == 'true'\n",
        "        self.clickStatus = row['clickStatus']\n",
        "        self.color_data = []\n",
        "        for typ in ['click', 'alt1', 'alt2']:\n",
        "            self.color_data.append({\n",
        "                'type': typ,\n",
        "                'Status': row['{}Status'.format(typ)],\n",
        "                'rep': self._get_color_rep(row, typ),\n",
        "                'speaker': int(row['{}LocS'.format(typ)]),\n",
        "                'listener': int(row['{}LocL'.format(typ)])})\n",
        "        self.colors = self._get_reps_in_order('Status')\n",
        "        self.listener_context = self._get_reps_in_order('listener')\n",
        "        self.speaker_context = self._get_reps_in_order('speaker')\n",
        "\n",
        "    def parse_turns(self):\n",
        "        \"\"\"\"\n",
        "        Turns the `contents` string into a list by splitting on\n",
        "        `TURN_BOUNDARY`.\n",
        "        Returns\n",
        "        -------\n",
        "        list of str\n",
        "        \"\"\"\n",
        "        return self.contents.split(TURN_BOUNDARY)\n",
        "\n",
        "    def display(self, typ='model'):\n",
        "        \"\"\"\n",
        "        Prints examples to the screen in an intuitive format: the\n",
        "        utterance text appears first, following by the three color\n",
        "        patches, with the target identified by a black border in the\n",
        "        'speaker' and 'model' variants.\n",
        "        Parameters\n",
        "        ----------\n",
        "        typ : str\n",
        "            Should be 'model', 'speaker', or 'listener'. This\n",
        "            determines the order the color patches are given. For\n",
        "            'speaker' and 'listener', this is the order in the corpus.\n",
        "            For 'model', it is a version with the two distractors\n",
        "            printed in their canonical order and the target given last.\n",
        "        Raises\n",
        "        ------\n",
        "        ValueError\n",
        "            If `typ` isn't one of 'model', 'speaker', 'listener'.\n",
        "        Prints\n",
        "        ------\n",
        "        text to standard output and three color patches as a\n",
        "        `matplotlib.pyplot` image. For notebook usage, this should\n",
        "        all embed nicely.\n",
        "        \"\"\"\n",
        "        print(self.contents)\n",
        "        if typ == 'model':\n",
        "            colors = self.colors\n",
        "            target_index = 2\n",
        "        elif typ == 'listener':\n",
        "            colors = self.listener_context\n",
        "            target_index = None\n",
        "        elif typ == 'speaker':\n",
        "            colors = self.speaker_context\n",
        "            target_index = self._get_target_index('speaker')\n",
        "        else:\n",
        "            raise ValueError('`typ` options: \"model\", \"listener\", \"speaker\"')\n",
        "\n",
        "        rgbs = [self._convert_hls_to_rgb(*c) for c in colors]\n",
        "\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(3, 1))\n",
        "\n",
        "        for i, c in enumerate(rgbs):\n",
        "            ec = c if (i != target_index or typ == 'listener') else \"black\"\n",
        "            patch = mpatch.Rectangle((0, 0), 1, 1, color=c, ec=ec, lw=8)\n",
        "            axes[i].add_patch(patch)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    def _get_color_rep(self, row, typ):\n",
        "        rep = []\n",
        "        for dim in ['H', 'L', 'S']:\n",
        "            colname = \"{}Col{}\".format(typ, dim)\n",
        "            rep.append(float(row[colname]))\n",
        "        if self.normalize_colors:\n",
        "            rep = self._scale_color(*rep)\n",
        "        return rep\n",
        "\n",
        "    def _convert_hls_to_rgb(self, h, l, s):\n",
        "        if not self.normalize_colors:\n",
        "            h, l, s = self._scale_color(h, l, s)\n",
        "        return colorsys.hls_to_rgb(h, l, s)\n",
        "\n",
        "    @staticmethod\n",
        "    def _scale_color(h, l, s):\n",
        "        return [h/360, l/100, s/100]\n",
        "\n",
        "    def _get_reps_in_order(self, field):\n",
        "        colors = [(d[field], d['rep']) for d in self.color_data]\n",
        "        return [rep for s, rep in sorted(colors)]\n",
        "\n",
        "    def _get_target_index(self, field):\n",
        "        for d in self.color_data:\n",
        "            if d['Status'] == 'target':\n",
        "                return d[field] - 1\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_row_alignment(rows):\n",
        "        \"\"\"\n",
        "        We expect all the dicts in `rows` to have the same keys and\n",
        "        values except for the keys associated with the messages. This\n",
        "        function tests this assumption holds.\n",
        "        \"\"\"\n",
        "        keys = set(rows[0].keys())\n",
        "        for row in rows[1:]:\n",
        "            if set(row.keys()) != keys:\n",
        "                raise RuntimeError(\n",
        "                    \"The dicts in the `rows` argument to `ColorsCorpusExample` \"\n",
        "                    \"must have all the same keys.\")\n",
        "        exempted = {'contents', 'msgTime',\n",
        "                    'numRawWords', 'numRawChars',\n",
        "                    'numCleanWords', 'numCleanChars'}\n",
        "        keys = keys - exempted\n",
        "        for row in rows[1: ]:\n",
        "            for key in keys:\n",
        "                if rows[0][key] != row[key]:\n",
        "                    raise RuntimeError(\n",
        "                        \"The dicts in the `rows` argument to `ColorsCorpusExample` \"\n",
        "                        \"must have all the same key values except for the keys \"\n",
        "                        \"associated with the message. The key {} has values {} \"\n",
        "                        \"and {}\".format(key, rows[0][key], row[key]))\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.contents"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:23.606957Z",
          "iopub.execute_input": "2022-04-30T09:15:23.607436Z",
          "iopub.status.idle": "2022-04-30T09:15:23.63848Z",
          "shell.execute_reply.started": "2022-04-30T09:15:23.607408Z",
          "shell.execute_reply": "2022-04-30T09:15:23.637738Z"
        },
        "trusted": true,
        "id": "wlXk-s_knatF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from Kaggle:\n",
        "corpus = ColorsCorpusReader(\"colors.csv\", word_count=None, normalize_colors=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:23.640057Z",
          "iopub.execute_input": "2022-04-30T09:15:23.640297Z",
          "iopub.status.idle": "2022-04-30T09:15:23.651826Z",
          "shell.execute_reply.started": "2022-04-30T09:15:23.640264Z",
          "shell.execute_reply": "2022-04-30T09:15:23.651103Z"
        },
        "trusted": true,
        "id": "mhTT9DoDnatH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute size of corpus:\n",
        "examples = list(corpus.read())\n",
        "print(\"Number of datapoints: {}\".format(len(examples)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:23.669387Z",
          "iopub.execute_input": "2022-04-30T09:15:23.66957Z",
          "iopub.status.idle": "2022-04-30T09:15:27.431624Z",
          "shell.execute_reply.started": "2022-04-30T09:15:23.669546Z",
          "shell.execute_reply": "2022-04-30T09:15:27.430848Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvZrg-ZInatH",
        "outputId": "8c6a3f28-b978-4d56-fd0c-2ac8edbc97ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of datapoints: 20177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Data\n",
        "\n",
        "We'll visualize an example datapoint from the listener perspective. Can you guess which color is being referred to?"
      ],
      "metadata": {
        "id": "J5YnqoWHnatI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex1 = next(corpus.read())\n",
        "ex1.display(typ='listener')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:27.433253Z",
          "iopub.execute_input": "2022-04-30T09:15:27.434008Z",
          "iopub.status.idle": "2022-04-30T09:15:28.600376Z",
          "shell.execute_reply.started": "2022-04-30T09:15:27.433967Z",
          "shell.execute_reply": "2022-04-30T09:15:28.59952Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "QV4ca9epnatI",
        "outputId": "77f3a481-0e88-4a8f-e2ee-60cc406bd6d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The darker blue one\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x72 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABFUlEQVR4nO3YsW1CMRRAUX+UCipShRXYhCqzpsomrJBUSRVaswAiFEiIq3Nau3hPunLhZc45oGT16AHg3kRNjqjJETU5oibn5drhfnN6+q+R4996ueXe7vD99LuOMcbX59u/+368/iZ2ff/ZXtzVS02OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IianGXO+egZ4K681OSImhxRkyNqckRNjqjJOQNHYRKDRd/3AwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the answer by visualizing the datapoint from the speaker's perspective:"
      ],
      "metadata": {
        "id": "1pUveiesnatJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex1 = next(corpus.read())\n",
        "ex1.display(typ='speaker')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:28.604907Z",
          "iopub.execute_input": "2022-04-30T09:15:28.605206Z",
          "iopub.status.idle": "2022-04-30T09:15:29.815626Z",
          "shell.execute_reply.started": "2022-04-30T09:15:28.605168Z",
          "shell.execute_reply": "2022-04-30T09:15:29.814825Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "7kjXLBzrnatJ",
        "outputId": "1851193a-3bdd-43dd-c688-aec03bdc9ebf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The darker blue one\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x72 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABLUlEQVR4nO3YMUrEUBRA0XyZSiutnC24EjvXajcrcQtOpZW2315kVMgQ5nJOmxTvweURMuacC5RcbT0ArE3U5IiaHFGTI2pydqcejjEu/tfInHP85b3nu/eL33VZluXp7fbXfR9uPhO7vnxc/7irS02OqMkRNTknv6m/u398Pdccqzke9luPwMZcanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9Tk7P7z8vGwP9ccsBqXmhxRkyNqcsacc+sZYFUuNTmiJkfU5IiaHFGTI2pyvgBwhhdAIEFGnQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Details: Dataset Splits\n",
        "\n",
        "Note that this dataset was constructed by generating colors under three separate conditions. In the \"far\" condition, the target color is not similar to either of the distractors. In the \"split\" condition, the target is similar to only one of the distractors. In the \"close\" condition, all three colors are similar to one another. We'll mostly ignore these splits in this homework, although you may wish to reference them in your report:"
      ],
      "metadata": {
        "id": "SdrBPH9dnatJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Condition type:\", examples[1].condition)\n",
        "examples[1].display()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:29.817626Z",
          "iopub.execute_input": "2022-04-30T09:15:29.817976Z",
          "iopub.status.idle": "2022-04-30T09:15:29.926004Z",
          "shell.execute_reply.started": "2022-04-30T09:15:29.817938Z",
          "shell.execute_reply": "2022-04-30T09:15:29.925237Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GlKRp6gXnatJ",
        "outputId": "c4e17893-c627-42f2-f88d-174c24603a2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condition type: far\n",
            "purple\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x72 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABLUlEQVR4nO3YwUnEUBRA0XyZbrQE3Qp24SytaJZOF4JbLUHr+TYgYxaBMNdztsniPbg8Qsacc4GSm70HgK2JmhxRkyNqckRNzuHSw7vvx6v/NfJ1+z7WvPf59nD1uy7Lstw/ffy57xgjseuc89ddXWpyRE2OqMm5+E3N//Dy/Lr3CKuczsdV77nU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMk57D0A+zudj3uPsCmXmhxRkyNqcsacc+8ZYFMuNTmiJkfU5IiaHFGTI2pyfgAdJBcf7IJsUgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Condition type:\", examples[3].condition)\n",
        "examples[3].display()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:29.93031Z",
          "iopub.execute_input": "2022-04-30T09:15:29.930571Z",
          "iopub.status.idle": "2022-04-30T09:15:30.053326Z",
          "shell.execute_reply.started": "2022-04-30T09:15:29.930535Z",
          "shell.execute_reply": "2022-04-30T09:15:30.052637Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "8mE_kuDunatK",
        "outputId": "44c8fd70-cbd1-479c-96f6-ad7d898ccd0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condition type: split\n",
            "lime\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x72 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABKklEQVR4nO3YQUrDUBRA0XzpbuyO7FTXUHAsuAad1h3Z9Xw3IDWDQOj1nGkyeA8uj5Ax51yg5GHvAWBroiZH1OSImhxRk3O49fDt8+Xuf428Pn+MNe9dTl93v+uyLMvp8vTnvmOMxK5zzl93danJETU5oibn5jc1/8P79+PeI6xyPl5XvedSkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oiZH1OSImhxRkyNqckRNjqjJETU5oibnsPcA7O98vO49wqZcanJETY6oyRlzzr1ngE251OSImhxRkyNqckRNjqjJ+QHLEhcAkintbgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Condition type:\", examples[2].condition)\n",
        "examples[2].display()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.057497Z",
          "iopub.execute_input": "2022-04-30T09:15:30.059723Z",
          "iopub.status.idle": "2022-04-30T09:15:30.170812Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.059666Z",
          "shell.execute_reply": "2022-04-30T09:15:30.170105Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "fDjwQXmWnatK",
        "outputId": "e501b047-815e-4937-b47f-c2ca8cc3f5a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condition type: close\n",
            "Medium pink ### the medium dark one\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x72 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABK0lEQVR4nO3YwUnEUBRA0XyZCnRlH4rDtGC9tiAO2ocrbeHbgIxZBMJcz9kmi/fg8ggZc84FSm72HgC2JmpyRE2OqMkRNTmHSw+/7z6v/tfI7df9WPPey+PH1e+6LMvy/P7w575jjMSuc85fd3WpyRE1OaIm5+I3Nf/D29Pr3iOscjyfVr3nUpMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaImR9TkiJocUZMjanJETY6oyRE1OaIm57D3AOzveD7tPcKmXGpyRE2OqMkZc869Z4BNudTkiJocUZMjanJETY6oyfkBPhUWwkgMDc4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series([ex.condition for ex in examples]).value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.174947Z",
          "iopub.execute_input": "2022-04-30T09:15:30.17714Z",
          "iopub.status.idle": "2022-04-30T09:15:30.234394Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.177097Z",
          "shell.execute_reply": "2022-04-30T09:15:30.23341Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdHjg74UnatK",
        "outputId": "48ee4839-afb8-412f-feb5-b62c5a7aef5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "far      6785\n",
              "split    6738\n",
              "close    6654\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has some other features that we'll ignore in this work. For example, some data was collected over multiple iterations of dialogue, and the `parse_turns` function defined above can be used to process this type of language data. We'll ignore these complications in our work and focus on building relatively straightforward speaker and listener models.\n",
        "\n",
        "## Helper Functions and Training Loop\n",
        "\n",
        "The following code defines some helper functions and classes for training Pytorch models. Most of the following code is fairly boilerplat and similar to what you've seen in other assignments throughout this course. You do not need to write any code for this section."
      ],
      "metadata": {
        "id": "Ar8IvqsRnatK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_SYMBOL = \"<s>\"\n",
        "END_SYMBOL = \"</s>\"\n",
        "UNK_SYMBOL = \"$UNK\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.238507Z",
          "iopub.execute_input": "2022-04-30T09:15:30.240702Z",
          "iopub.status.idle": "2022-04-30T09:15:30.24653Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.240645Z",
          "shell.execute_reply": "2022-04-30T09:15:30.245704Z"
        },
        "trusted": true,
        "id": "f9ts56HynatL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def progress_bar(msg, verbose=True):\n",
        "    # Simple over-writing progress bar.\n",
        "    if verbose:\n",
        "        sys.stderr.write('\\r')\n",
        "        sys.stderr.write(msg)\n",
        "        sys.stderr.flush()\n",
        "        \n",
        "def randvec(n=50, lower=-0.5, upper=0.5):\n",
        "    # Returns a random vector of length `n`. `w` is ignored.\n",
        "    return np.array([random.uniform(lower, upper) for i in range(n)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.251926Z",
          "iopub.execute_input": "2022-04-30T09:15:30.252268Z",
          "iopub.status.idle": "2022-04-30T09:15:30.262377Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.252233Z",
          "shell.execute_reply": "2022-04-30T09:15:30.26167Z"
        },
        "trusted": true,
        "id": "nk4HMQGinatL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TorchModelBase:\n",
        "    def __init__(self,\n",
        "            batch_size=1028,\n",
        "            max_iter=1000,\n",
        "            eta=0.001,\n",
        "            optimizer_class=torch.optim.Adam,\n",
        "            l2_strength=0,\n",
        "            gradient_accumulation_steps=1,\n",
        "            max_grad_norm=None,\n",
        "            warm_start=False,\n",
        "            early_stopping=False,\n",
        "            validation_fraction=0.1,\n",
        "            shuffle_train=True,\n",
        "            n_iter_no_change=10,\n",
        "            tol=1e-5,\n",
        "            device=None,\n",
        "            display_progress=True,\n",
        "            **optimizer_kwargs):\n",
        "        \"\"\"\n",
        "        Base class for all the PyTorch-based models.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size: int\n",
        "            Number of examples per batch. Batching is handled by a\n",
        "            `torch.utils.data.DataLoader`. Final batches can have fewer\n",
        "            examples, depending on the total number of examples in the\n",
        "            dataset.\n",
        "\n",
        "        max_iter: int\n",
        "            Maximum number of training iterations. This will interact\n",
        "            with `early_stopping`, `n_iter_no_change`, and `tol` in the\n",
        "            sense that this limit will be reached if and only if and\n",
        "            conditions triggered by those other parameters are not met.\n",
        "\n",
        "        eta : float\n",
        "            Learning rate for the optimizer.\n",
        "\n",
        "        optimizer_class: `torch.optimizer.Optimizer`\n",
        "            Any PyTorch optimizer should work. Additional arguments\n",
        "            can be passed to this object via `**optimizer_kwargs`. The\n",
        "            optimizer itself is built by `self.build_optimizer` when\n",
        "            `fit` is called.\n",
        "\n",
        "        l2_strength: float\n",
        "            L2 regularization parameters for the optimizer. The default\n",
        "            of 0 means no regularization, and larger values correspond\n",
        "            to stronger regularization.\n",
        "\n",
        "        gradient_accumulation_steps: int\n",
        "            Controls how often the model parameters are updated during\n",
        "            learning. For example, with `gradient_accumulation_steps=2`,\n",
        "            the parameters are updated after every other batch. The primary\n",
        "            use case for `gradient_accumulation_steps > 1` is where the\n",
        "            model is very large, so only small batches of examples can be\n",
        "            fit into memory. The updates based on these small batches can\n",
        "            have high variance, so accumulating a few batches before\n",
        "            updating can smooth the process out.\n",
        "\n",
        "        max_grad_norm: None or float\n",
        "            If not `None`, then `torch.nn.utils.clip_grad_norm_` is used\n",
        "            to clip all the model parameters to within the range set\n",
        "            by this value. This is a kind of brute-force way of keeping\n",
        "            the parameter values from growing absurdly large or small.\n",
        "\n",
        "        warm_start: bool\n",
        "            If `False`, then repeated calls to `fit` will reset all the\n",
        "            optimization settings: the model parameters, the optimizer,\n",
        "            and the metadata we collect during optimization. If `True`,\n",
        "            then calling `fit` twice with `max_iter=N` should be the same\n",
        "            as calling fit once with `max_iter=N*2`.\n",
        "\n",
        "        early_stopping: bool\n",
        "            If `True`, then `validation_fraction` of the data given to\n",
        "            `fit` are held out and used to assess the model after every\n",
        "            epoch. The best scoring model is stored in an attribute\n",
        "            `best_parameters`. If an improvement of at least `self.tol`\n",
        "            isn't seen after `n_iter_no_change` iterations, then training\n",
        "            stops and `self.model` is set to use `best_parameters`.\n",
        "\n",
        "        validation_fraction: float\n",
        "            Percentage of the data given to `fit` to hold out for use in\n",
        "            early stopping. Ignored if `early_stopping=False`\n",
        "\n",
        "        shuffle_train: bool\n",
        "            Whether to shuffle the training data.\n",
        "\n",
        "        n_iter_no_change: int\n",
        "            Number of epochs used to control convergence and early\n",
        "            stopping. Where `early_stopping=True`, training stops if an\n",
        "            improvement of more than `self.tol` isn't seen after this\n",
        "            many epochs. If `early_stopping=False`, then training stops\n",
        "            if the epoch error doesn't drop by at least `self.tol` after\n",
        "            this many epochs.\n",
        "\n",
        "        tol: float\n",
        "            Value used to control `early_stopping` and convergence.\n",
        "\n",
        "        device: str or None\n",
        "            Used to set the device on which the PyTorch computations will\n",
        "            be done. If `device=None`, this will choose a CUDA device if\n",
        "            one is available, else the CPU is used.\n",
        "\n",
        "        display_progress: bool\n",
        "            Whether to print optimization information incrementally to\n",
        "            `sys.stderr` during training.\n",
        "\n",
        "        **optimizer_kwargs: kwargs\n",
        "            Any additional keywords given to the model will be passed to\n",
        "            the optimizer -- see `self.build_optimizer`. The intent is to\n",
        "            make it easy to tune these as hyperparameters will still\n",
        "            allowing the user to specify just `optimizer_class` rather\n",
        "            than setting up a full optimizer.\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        params: list\n",
        "             All the keyword arguments are parameters and, with the\n",
        "             exception of `display_progress`, their names are added to\n",
        "             this list to support working with them using tools from\n",
        "             `sklearn.model_selection`.\n",
        "\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.max_iter = max_iter\n",
        "        self.eta = eta\n",
        "        self.optimizer_class = optimizer_class\n",
        "        self.l2_strength = l2_strength\n",
        "        self.gradient_accumulation_steps = max([gradient_accumulation_steps, 1])\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.warm_start = warm_start\n",
        "        self.early_stopping = early_stopping\n",
        "        self.validation_fraction = validation_fraction\n",
        "        self.shuffle_train = shuffle_train\n",
        "        self.n_iter_no_change = n_iter_no_change\n",
        "        self.tol = tol\n",
        "        if device is None:\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.device = torch.device(device)\n",
        "        self.display_progress = display_progress\n",
        "        self.optimizer_kwargs = optimizer_kwargs\n",
        "        for k, v in self.optimizer_kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "        self.params = [\n",
        "            'batch_size',\n",
        "            'max_iter',\n",
        "            'eta',\n",
        "            'optimizer_class',\n",
        "            'l2_strength',\n",
        "            'gradient_accumulation_steps',\n",
        "            'max_grad_norm',\n",
        "            'validation_fraction',\n",
        "            'early_stopping',\n",
        "            'n_iter_no_change',\n",
        "            'warm_start',\n",
        "            'tol']\n",
        "        self.params += list(optimizer_kwargs.keys())\n",
        "\n",
        "    def build_dataset(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Subclasses are required to define this method. Perhaps the most\n",
        "        important design note is that the function should be prepared to\n",
        "        return datasets that are appropriate for both training and\n",
        "        prediction. For training, we expect `*args` to have labels in\n",
        "        final position. For prediction, we expect all of `*args` to be\n",
        "        model inputs. For example, in a simple classifier, we expect\n",
        "        `*args` to be a pair `(X, y)` for training and so this method\n",
        "        should return something like:\n",
        "\n",
        "        `torch.utils.data.TensorDataset(X, y)`\n",
        "\n",
        "        For prediction, we get only `X`, so we should return\n",
        "\n",
        "        `torch.utils.data.TensorDataset(X)`\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        *args: any arguments to be used to create the dataset\n",
        "\n",
        "        **kwargs: any desired keyword arguments\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `torch.utils.data.Dataset` or a custom subclass thereof\n",
        "\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def build_graph(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Build the core computational graph. This is called only after\n",
        "        `fit` is called. The return value of this function becomes the\n",
        "        the `self.model` attribute.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        *args: any arguments to be used to create the dataset\n",
        "\n",
        "        **kwargs: any desired keyword arguments\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        nn.Module or subclass thereof\n",
        "\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def score(self, *args):\n",
        "        \"\"\"\n",
        "        Required by the `sklearn.model_selection` tools. This function\n",
        "        needs to take the same arguments as `fit`. For `*args` is usually\n",
        "        an `(X, y)` pair of features and labels, and `self.predict(X)`\n",
        "        is called and then some kind of scoring function is used to\n",
        "        compare those predictions with `y`. The return value should be\n",
        "        some kind of appropriate score for the model in question.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        For early stopping, we use this function to get scores and\n",
        "        assume that larger scores are better. This would conflict with\n",
        "        using, say, a mean-squared-error scoring function.\n",
        "\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def build_optimizer(self):\n",
        "        \"\"\"\n",
        "        Builds the optimizer. This function is called only when `fit`\n",
        "        is called.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.optimizer.Optimizer\n",
        "\n",
        "        \"\"\"\n",
        "        return self.optimizer_class(\n",
        "            self.model.parameters(),\n",
        "            lr=self.eta,\n",
        "            weight_decay=self.l2_strength,\n",
        "            **self.optimizer_kwargs)\n",
        "\n",
        "    def fit(self, *args):\n",
        "        \"\"\"\n",
        "        Generic optimization method.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        *args: list of objects\n",
        "            We assume that the final element of args give the labels\n",
        "            and all the preceding elements give the system inputs.\n",
        "            For regular supervised learning, this is like (X, y), but\n",
        "            we allow for models that might use multiple data structures\n",
        "            for their inputs.\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        model: nn.Module or subclass thereof\n",
        "            Set by `build_graph`. If `warm_start=True`, then this is\n",
        "            initialized only by the first call to `fit`.\n",
        "\n",
        "        optimizer: torch.optimizer.Optimizer\n",
        "            Set by `build_optimizer`. If `warm_start=True`, then this is\n",
        "            initialized only by the first call to `fit`.\n",
        "\n",
        "        errors: list of float\n",
        "            List of errors. If `warm_start=True`, then this is\n",
        "            initialized only by the first call to `fit`. Thus, where\n",
        "            `max_iter=5`, if we call `fit` twice with `warm_start=True`,\n",
        "            then `errors` will end up with 10 floats in it.\n",
        "\n",
        "        validation_scores: list\n",
        "            List of scores. This is filled only if `early_stopping=True`.\n",
        "            If `warm_start=True`, then this is initialized only by the\n",
        "            first call to `fit`. Thus, where `max_iter=5`, if we call\n",
        "            `fit` twice with `warm_start=True`, then `validation_scores`\n",
        "            will end up with 10 floats in it.\n",
        "\n",
        "        no_improvement_count: int\n",
        "            Used to control early stopping and convergence. These values\n",
        "            are controlled by `_update_no_improvement_count_early_stopping`\n",
        "            or `_update_no_improvement_count_errors`.  If `warm_start=True`,\n",
        "            then this is initialized only by the first call to `fit`. Thus,\n",
        "            in that situation, the values could accumulate across calls to\n",
        "            `fit`.\n",
        "\n",
        "        best_error: float\n",
        "           Used to control convergence. Smaller is assumed to be better.\n",
        "           If `warm_start=True`, then this is initialized only by the first\n",
        "           call to `fit`. It will be reset by\n",
        "           `_update_no_improvement_count_errors` depending on how the\n",
        "           optimization is proceeding.\n",
        "\n",
        "        best_score: float\n",
        "           Used to control early stopping. If `warm_start=True`, then this\n",
        "           is initialized only by the first call to `fit`. It will be reset\n",
        "           by `_update_no_improvement_count_early_stopping` depending on how\n",
        "           the optimization is proceeding. Important: we currently assume\n",
        "           that larger scores are better. As a result, we will not get the\n",
        "           correct results for, e.g., a scoring function based in\n",
        "           `mean_squared_error`. See `self.score` for additional details.\n",
        "\n",
        "        best_parameters: dict\n",
        "            This is a PyTorch state dict. It is used if and only if\n",
        "            `early_stopping=True`. In that case, it is updated whenever\n",
        "            `best_score` is improved numerically. If the early stopping\n",
        "            criteria are met, then `self.model` is reset to contain these\n",
        "            parameters before `fit` exits.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "\n",
        "        \"\"\"\n",
        "        if self.early_stopping:\n",
        "            args, dev = self._build_validation_split(\n",
        "                *args, validation_fraction=self.validation_fraction)\n",
        "\n",
        "        # Dataset:\n",
        "        dataset = self.build_dataset(*args)\n",
        "        dataloader = self._build_dataloader(dataset, shuffle=self.shuffle_train)\n",
        "\n",
        "        # Set up parameters needed to use the model. This is a separate\n",
        "        # function to support using pretrained models for prediction,\n",
        "        # where it might not be desirable to call `fit`.\n",
        "        self.initialize()\n",
        "\n",
        "        # Make sure the model is where we want it:\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.model.train()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        for iteration in range(1, self.max_iter+1):\n",
        "\n",
        "            epoch_error = 0.0\n",
        "\n",
        "            for batch_num, batch in enumerate(dataloader, start=1):\n",
        "\n",
        "                batch = [x.to(self.device, non_blocking=True) for x in batch]\n",
        "\n",
        "                X_batch = batch[: -1]\n",
        "                y_batch = batch[-1]\n",
        "\n",
        "                batch_preds = self.model(*X_batch)\n",
        "\n",
        "                err = self.loss(batch_preds, y_batch)\n",
        "\n",
        "                if self.gradient_accumulation_steps > 1 and \\\n",
        "                  self.loss.reduction == \"mean\":\n",
        "                    err /= self.gradient_accumulation_steps\n",
        "\n",
        "                err.backward()\n",
        "\n",
        "                epoch_error += err.item()\n",
        "\n",
        "                if batch_num % self.gradient_accumulation_steps == 0 or \\\n",
        "                  batch_num == len(dataloader):\n",
        "                    if self.max_grad_norm is not None:\n",
        "                        torch.nn.utils.clip_grad_norm_(\n",
        "                            self.model.parameters(), self.max_grad_norm)\n",
        "                    self.optimizer.step()\n",
        "                    self.optimizer.zero_grad()\n",
        "\n",
        "            # Stopping criteria:\n",
        "\n",
        "            if self.early_stopping:\n",
        "                self._update_no_improvement_count_early_stopping(*dev)\n",
        "                if self.no_improvement_count > self.n_iter_no_change:\n",
        "                    progress_bar(\n",
        "                        \"Stopping after epoch {}. Validation score did \"\n",
        "                        \"not improve by tol={} for more than {} epochs. \"\n",
        "                        \"Final error is {}\".format(iteration, self.tol,\n",
        "                            self.n_iter_no_change, epoch_error),\n",
        "                        verbose=self.display_progress)\n",
        "                    break\n",
        "\n",
        "            else:\n",
        "                self._update_no_improvement_count_errors(epoch_error)\n",
        "                if self.no_improvement_count > self.n_iter_no_change:\n",
        "                    progress_bar(\n",
        "                        \"Stopping after epoch {}. Training loss did \"\n",
        "                        \"not improve more than tol={}. Final error \"\n",
        "                        \"is {}.\".format(iteration, self.tol, epoch_error),\n",
        "                        verbose=self.display_progress)\n",
        "                    break\n",
        "\n",
        "            progress_bar(\n",
        "                \"Finished epoch {} of {}; error is {}\".format(\n",
        "                    iteration, self.max_iter, epoch_error),\n",
        "                verbose=self.display_progress)\n",
        "\n",
        "        if self.early_stopping:\n",
        "            self.model.load_state_dict(self.best_parameters)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"\n",
        "        Method called by `fit` to establish core attributes. To use a\n",
        "        pretrained model without calling `fit`, one can use this\n",
        "        method.\n",
        "\n",
        "        \"\"\"\n",
        "        if not self.warm_start or not hasattr(self, \"model\"):\n",
        "            self.model = self.build_graph()\n",
        "            # This device move has to happen before the optimizer is built:\n",
        "            # https://pytorch.org/docs/master/optim.html#constructing-it\n",
        "            self.model.to(self.device)\n",
        "            self.optimizer = self.build_optimizer()\n",
        "            self.errors = []\n",
        "            self.validation_scores = []\n",
        "            self.no_improvement_count = 0\n",
        "            self.best_error = np.inf\n",
        "            self.best_score = -np.inf\n",
        "            self.best_parameters = None\n",
        "\n",
        "    @staticmethod\n",
        "    def _build_validation_split(*args, validation_fraction=0.2):\n",
        "        \"\"\"\n",
        "        Split `*args` into train and dev portions for early stopping.\n",
        "        We use `train_test_split`. For args of length N, then delivers\n",
        "        N*2 objects, arranged as\n",
        "\n",
        "        X1_train, X1_test, X2_train, X2_test, ..., y_train, y_test\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        *args: List of objects to split.\n",
        "\n",
        "        validation_fraction: float\n",
        "            Percentage of the examples to use for the dev portion. In\n",
        "            `fit`, this is determined by `self.validation_fraction`.\n",
        "            We give it as an argument here to facilitate unit testing.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Pair of tuples `train` and `dev`\n",
        "\n",
        "        \"\"\"\n",
        "        if validation_fraction == 1.0:\n",
        "            return args, args\n",
        "        results = train_test_split(*args, test_size=validation_fraction)\n",
        "        train = results[::2]\n",
        "        dev = results[1::2]\n",
        "        return train, dev\n",
        "\n",
        "    def _build_dataloader(self, dataset, shuffle=True):\n",
        "        \"\"\"\n",
        "        Internal method used to create a dataloader from a dataset.\n",
        "        This is used by `fit` and `_predict`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: torch.utils.data.Dataset\n",
        "\n",
        "        shuffle: bool\n",
        "            When training, this is `True`. For prediction, this is\n",
        "            crucially set to `False` so that the examples are not\n",
        "            shuffled out of order with respect to labels that might\n",
        "            be used for assessment.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.utils.data.DataLoader\n",
        "\n",
        "        \"\"\"\n",
        "        if hasattr(dataset, \"collate_fn\"):\n",
        "            collate_fn = dataset.collate_fn\n",
        "        else:\n",
        "            collate_fn = None\n",
        "        dataloader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=shuffle,\n",
        "            pin_memory=True,\n",
        "            collate_fn=collate_fn)\n",
        "        return dataloader\n",
        "\n",
        "    def _update_no_improvement_count_early_stopping(self, *dev):\n",
        "        \"\"\"\n",
        "        Internal method used by `fit` to control early stopping.\n",
        "        The method uses `self.score(*dev)` for scoring and updates\n",
        "        `self.validation_scores`, `self.no_improvement_count`,\n",
        "        `self.best_score`, `self.best_parameters` as appropriate.\n",
        "\n",
        "        \"\"\"\n",
        "        score = self.score(*dev)\n",
        "        self.validation_scores.append(score)\n",
        "        # If the score isn't at least `self.tol` better, increment:\n",
        "        if score < (self.best_score + self.tol):\n",
        "            self.no_improvement_count += 1\n",
        "        else:\n",
        "            self.no_improvement_count = 0\n",
        "        # If the current score is numerically better than all previous\n",
        "        # scores, update the best parameters:\n",
        "        if score > self.best_score:\n",
        "            self.best_parameters = copy.deepcopy(self.model.state_dict())\n",
        "            self.best_score = score\n",
        "        self.model.train()\n",
        "\n",
        "    def _update_no_improvement_count_errors(self, epoch_error):\n",
        "        \"\"\"\n",
        "        Internal method used by `fit` to control convergence.\n",
        "        The method uses `epoch_error`, `self.best_error`, and\n",
        "        `self.tol` to make decisions, and it updates `self.errors`,\n",
        "        `self.no_improvement_count`, and `self.best_error` as\n",
        "        appropriate.\n",
        "\n",
        "        \"\"\"\n",
        "        if epoch_error > (self.best_error - self.tol):\n",
        "            self.no_improvement_count += 1\n",
        "        else:\n",
        "            self.no_improvement_count = 0\n",
        "        if epoch_error < self.best_error:\n",
        "            self.best_error = epoch_error\n",
        "        self.errors.append(epoch_error)\n",
        "\n",
        "    def _predict(self, *args, device=None):\n",
        "        \"\"\"\n",
        "        Internal method that subclasses are expected to use to define\n",
        "        their own `predict` functions. The hope is that this method\n",
        "        can do all the data organization and other details, allowing\n",
        "        subclasses to have compact predict methods that just encode\n",
        "        the core logic specific to them.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        *args: system inputs\n",
        "\n",
        "        device: str or None\n",
        "            Allows the user to temporarily change the device used\n",
        "            during prediction. This is useful if predictions require a\n",
        "            lot of memory and so are better done on the CPU. After\n",
        "            prediction is done, the model is returned to `self.device`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        The precise return value depends on the nature of the predictions.\n",
        "        If the predictions have the same shape across all batches, then\n",
        "        we return a single tensor concatenation of them. If the shape\n",
        "        can vary across batches, as is common for sequence prediction,\n",
        "        then we return a list of tensors of varying length.\n",
        "\n",
        "        \"\"\"\n",
        "        device = self.device if device is None else torch.device(device)\n",
        "\n",
        "        # Dataset:\n",
        "        dataset = self.build_dataset(*args)\n",
        "        dataloader = self._build_dataloader(dataset, shuffle=False)\n",
        "\n",
        "        # Model:\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                X = [x.to(device, non_blocking=True) for x in batch]\n",
        "                preds.append(self.model(*X))\n",
        "\n",
        "        # Make sure the model is back on the instance device:\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # If the batch outputs differ only in their batch size, sharing\n",
        "        # all other dimensions, then we can concatenate them and maintain\n",
        "        # a tensor. For simple classification problems, this should hold.\n",
        "        if all(x.shape[1: ] == preds[0].shape[1: ] for x in preds[1: ]):\n",
        "            return torch.cat(preds, axis=0)\n",
        "        # The batch outputs might differ along other dimensions. This is\n",
        "        # common for sequence prediction, where different batches might\n",
        "        # have different max lengths, since we pad on a per-batch basis.\n",
        "        # In this case, we can't concatenate them, so we return a list\n",
        "        # of the predictions, where each prediction is a tensor. Note:\n",
        "        # the predictions might still be padded and so need trimming on a\n",
        "        # per example basis.\n",
        "        else:\n",
        "            return [p for batch in preds for p in batch]\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        params = self.params.copy()\n",
        "        # Obligatorily add `vocab` so that sklearn passes it in when\n",
        "        # creating new model instances during cross-validation:\n",
        "        if hasattr(self, 'vocab'):\n",
        "            params += ['vocab']\n",
        "        return {p: getattr(self, p) for p in params}\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for key, val in params.items():\n",
        "            if key not in self.params:\n",
        "                raise ValueError(\n",
        "                    \"{} is not a parameter for {}. For the list of \"\n",
        "                    \"available parameters, use `self.params`.\".format(\n",
        "                        key, self.__class__.__name__))\n",
        "            else:\n",
        "                setattr(self, key, val)\n",
        "        return self\n",
        "\n",
        "    def to_pickle(self, output_filename):\n",
        "        \"\"\"\n",
        "        Serialize the entire class instance. Importantly, this is\n",
        "        different from using the standard `torch.save` method:\n",
        "\n",
        "        torch.save(self.model.state_dict(), output_filename)\n",
        "\n",
        "        The above stores only the underlying model parameters. In\n",
        "        contrast, the current method ensures that all of the model\n",
        "        parameters are on the CPU and then stores the full instance.\n",
        "        This is necessary to ensure that we retain all the information\n",
        "        needed to read new examples, do additional training, make\n",
        "        predictions, and so forth.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        output_filename : str\n",
        "            Full path for the output file.\n",
        "\n",
        "        \"\"\"\n",
        "        self.model = self.model.cpu()\n",
        "        with open(output_filename, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    @staticmethod\n",
        "    def from_pickle(src_filename):\n",
        "        \"\"\"\n",
        "        Load an entire class instance onto the CPU. This also sets\n",
        "        `self.warm_start=True` so that the loaded parameters are used\n",
        "        if `fit` is called.\n",
        "\n",
        "        Importantly, this is different from recommended PyTorch method:\n",
        "\n",
        "        self.model.load_state_dict(torch.load(src_filename))\n",
        "\n",
        "        We cannot reliably do this with new instances, because we need\n",
        "        to see new examples in order to set some of the model\n",
        "        dimensionalities and obtain information about what the class\n",
        "        labels are. Thus, the current method loads an entire serialized\n",
        "        class as created by `to_pickle`.\n",
        "\n",
        "        The training and prediction code move the model parameters to\n",
        "        `self.device`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        src_filename : str\n",
        "            Full path to the serialized model file.\n",
        "\n",
        "        \"\"\"\n",
        "        with open(src_filename, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def __repr__(self):\n",
        "        param_str = [\"{}={}\".format(a, getattr(self, a)) for a in self.params]\n",
        "        param_str = \",\\n\\t\".join(param_str)\n",
        "        return \"{}(\\n\\t{})\".format(self.__class__.__name__, param_str)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.266544Z",
          "iopub.execute_input": "2022-04-30T09:15:30.266749Z",
          "iopub.status.idle": "2022-04-30T09:15:30.322225Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.266723Z",
          "shell.execute_reply": "2022-04-30T09:15:30.321558Z"
        },
        "trusted": true,
        "id": "e2dAIrrmnatL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch dataset for contextual color describers. The primary\n",
        "    function of this dataset is to organize the raw data into\n",
        "    batches of Tensors of the appropriate shape and type. When\n",
        "    using this dataset with `torch.utils.data.DataLoader`, it is\n",
        "    crucial to supply the `collate_fn` method as the argument for\n",
        "    the `DataLoader.collate_fn` parameter.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    color_seqs : list of lists of lists of floats, or np.array\n",
        "        Dimension (m, n, p) where m is the number of examples, n is\n",
        "        the number of colors in each context, and p is the length\n",
        "        of the color representations.\n",
        "\n",
        "    word_seqs : list of list of int\n",
        "        Dimension m, the number of examples. The length of each\n",
        "        sequence can vary.\n",
        "\n",
        "    ex_lengths : list of int\n",
        "        Dimension m. Each value gives the length of the corresponding\n",
        "        word sequence in `word_seqs`.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, color_seqs, word_seqs, ex_lengths):\n",
        "        assert len(color_seqs) == len(ex_lengths)\n",
        "        assert len(color_seqs) == len(word_seqs)\n",
        "        self.color_seqs = color_seqs\n",
        "        self.word_seqs = word_seqs\n",
        "        self.ex_lengths = ex_lengths\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch):\n",
        "        \"\"\"\n",
        "        Function for creating batches.\n",
        "\n",
        "        Parameter\n",
        "        ---------\n",
        "        batch : tuple of length 3\n",
        "            Contains the `color_seqs`, `word_seqs`, and `ex_lengths`,\n",
        "            all as lists or similar Python iterables. The function\n",
        "            turns them into Tensors.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        color_seqs : torch.FloatTensor.\n",
        "             The shape is `(m, n, p)` where `m` is the batch_size,\n",
        "             `n` is the number of colors in each context, and `p` is\n",
        "             the color dimensionality.\n",
        "\n",
        "        word_seqs : torch.LongTensor\n",
        "            This is a padded sequence, dimension (m, k), where `m` is\n",
        "            the batch_size and `k` is the length of the longest sequence\n",
        "            in the batch.\n",
        "\n",
        "        ex_lengths : torch.LongTensor\n",
        "            The true lengths of each sequence in `word_seqs. This will\n",
        "            have shape `(m, )`, where `m` is the batch_size.\n",
        "\n",
        "        targets :  torch.LongTensor\n",
        "            This is a padded sequence, dimension (m, k-1), where `m` is\n",
        "            the batch_size and `k` is the length of the longest sequence\n",
        "            in the batch. The targets match `word_seqs` except we drop the\n",
        "            first symbol, as it is always START_SYMBOL. When the loss is\n",
        "            calculated, we compare this sequence to `word_seqs` excluding\n",
        "            the final character, which is always the END_SYMBOL. The result\n",
        "            is that each timestep t is trained to predict the symbol\n",
        "            at t+1.\n",
        "\n",
        "        \"\"\"\n",
        "        color_seqs, word_seqs, ex_lengths = zip(*batch)\n",
        "        # Conversion to Tensors:\n",
        "        color_seqs = torch.FloatTensor(color_seqs)\n",
        "        word_seqs = [torch.LongTensor(seq) for seq in word_seqs]\n",
        "        ex_lengths = torch.LongTensor(ex_lengths)\n",
        "        # Targets as next-word predictions:\n",
        "        targets = [x[1:, ] for x in word_seqs]\n",
        "        # Padding\n",
        "        word_seqs = torch.nn.utils.rnn.pad_sequence(\n",
        "            word_seqs, batch_first=True)\n",
        "        targets = torch.nn.utils.rnn.pad_sequence(\n",
        "            targets, batch_first=True)\n",
        "        return color_seqs, word_seqs, ex_lengths, targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.color_seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.color_seqs[idx], self.word_seqs[idx], self.ex_lengths[idx]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.323425Z",
          "iopub.execute_input": "2022-04-30T09:15:30.323819Z",
          "iopub.status.idle": "2022-04-30T09:15:30.336254Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.323783Z",
          "shell.execute_reply": "2022-04-30T09:15:30.335486Z"
        },
        "trusted": true,
        "id": "U4R6oNHInatO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model\n",
        "\n",
        "We'll implement the speaker model depicted on the right side of the diagram below. In this model, color representations are fed into an encoder LSTM, which is connected to a decoder LSTM that generates utterances conditioned on the color representation. The model described in Monroe, et al. (2017) concatenates the hidden representation of the encoder model with word representations during teacher-forcing; we will leave this part of the model as an optional extension as part of the report.\n",
        "\n",
        "![Screen Shot 2022-04-29 at 11.12.04 PM.png](attachment:d5c3e6f8-0ba6-468c-b036-4883253ddeec.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "RFYuH6SwnatP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder-Decoder \n",
        "We'll begin by defining the encoder and decoder models. You should only need to fill in a few lines of fairly straightforward code here: "
      ],
      "metadata": {
        "id": "IjsSKYdpSO7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, color_dim, hidden_dim):\n",
        "        \"\"\"\n",
        "        Simple Encoder model based on a GRU cell.\n",
        "        ----------\n",
        "        color_dim : int\n",
        "        hidden_dim : int\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.color_dim = color_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \"\"\"\n",
        "        YOUR CODE HERE\n",
        "          - Define a single-layer LSTM/GRU with dimensions as above\n",
        "          - Set batch_first=True\n",
        "        \"\"\"\n",
        "        # BEGIN SOLUTION\n",
        "        self.lstm = nn.LSTM(color_dim,hidden_dim,batch_first=True)\n",
        "        # END SOLUTION\n",
        "\n",
        "    def forward(self, color_seqs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : torch.FloatTensor\n",
        "            The shape is `(m, n, p)` where `m` is the batch_size,\n",
        "             `n` is the number of colors in each context, and `p` is\n",
        "             the color dimensionality.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        hidden : torch.FloatTensor\n",
        "            These are the final hidden state of the RNN for this batch,\n",
        "            shape `(m, p) where `m` is the batch_size and `p` is\n",
        "             the color dimensionality.\n",
        "\n",
        "        YOUR CODE HERE\n",
        "          - Call the LSTM/GRU defined above\n",
        "          - Return the hidden states and discard the output\n",
        "        \"\"\"\n",
        "        # BEGIN SOLUTION\n",
        "        out, hidden = self.lstm(color_seqs)\n",
        "        # END SOLUTION\n",
        "        return hidden"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.337164Z",
          "iopub.execute_input": "2022-04-30T09:15:30.337409Z",
          "iopub.status.idle": "2022-04-30T09:15:30.348499Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.337377Z",
          "shell.execute_reply": "2022-04-30T09:15:30.347729Z"
        },
        "trusted": true,
        "id": "U4ZnM6cknatP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decoder is similar to the encoder, with the addition of a dense output layer. You'll also need to use `pack_padded_sequence` and `pad_packed_sequence` during training. Note that our code handles all of the tensor operations like slicing and transposing, so you only need to pass your embeddings into a series of functions. You do not need to call `pack_padded_sequence` during inference."
      ],
      "metadata": {
        "id": "xBW89TCdnatP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "            vocab_size,\n",
        "            embed_dim,\n",
        "            hidden_dim,\n",
        "            embedding=None,\n",
        "            freeze_embedding=False):\n",
        "        \"\"\"\n",
        "        Simple Decoder model based on a GRU cell. The hidden\n",
        "        representations of the GRU are passed through a dense linear\n",
        "        layer, and those logits are used to train the language model\n",
        "        according to a softmax objective in `ContextualColorDescriber`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        vocab_size : int\n",
        "\n",
        "        embed_dim : int\n",
        "\n",
        "        hidden_dim : int\n",
        "\n",
        "        embedding : np.array or None\n",
        "            If `None`, a random embedding is created. If `np.array`, this\n",
        "            value becomes the embedding.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.freeze_embedding = freeze_embedding\n",
        "        self.embedding = self._define_embedding(embedding, self.vocab_size, embed_dim, self.freeze_embedding)\n",
        "        self.embed_dim = self.embedding.embedding_dim\n",
        "        \n",
        "        \"\"\"\n",
        "        YOUR CODE HERE\n",
        "          - Define another single-layer LSTM/GRU\n",
        "          - Add an output layer which maps onto self.vocab_size\n",
        "        \"\"\"\n",
        "        # BEGIN SOLUTION\n",
        "        self.lstm_d = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "        # END SOLUTION\n",
        "\n",
        "    def forward(self, word_seqs, seq_lengths=None, hidden=None, target_colors=None):\n",
        "        \"\"\"\n",
        "        Core computation for the model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        word_seqs : torch.LongTensor\n",
        "            This is a padded sequence, dimension (m, k), where k is\n",
        "            the length of the longest sequence in the batch. The `forward`\n",
        "            method uses `self.get_embeddings` to map these indices to their\n",
        "            embeddings.\n",
        "\n",
        "        seq_lengths : torch.LongTensor\n",
        "            Shape (m, ) where `m` is the number of examples in the batch.\n",
        "\n",
        "        hidden : torch.FloatTensor\n",
        "            Shape `(m, self.hidden_dim)`. When training, this is always the\n",
        "            final state of the `Encoder`. During prediction, this might be\n",
        "            recursively computed as the sequence is processed.\n",
        "\n",
        "        target_colors : torch.FloatTensor\n",
        "            Dimension (m, c), where m is the number of examples and\n",
        "            c is the dimensionality of the color representations.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output : torch.FloatTensor\n",
        "            The full sequence of outputs states. When we are training, the\n",
        "            shape is `(m, hidden_dim, k)` to accommodate the expectations\n",
        "            of the loss function. During prediction, the shape is\n",
        "            `(m, k, hidden_dim)`. In both cases, m is the number of examples in\n",
        "            the batch and `k` is the maximum length of sequences in this batch.\n",
        "\n",
        "        hidden : torch.FloatTensor\n",
        "            The final output state of the network. Shape `(m, hidden_dim)`\n",
        "            where m is the number of examples in the batch.\n",
        "\n",
        "        \"\"\"\n",
        "        embs = self.get_embeddings(word_seqs, target_colors=target_colors)\n",
        "\n",
        "        if self.training:\n",
        "            \"\"\"\n",
        "            YOUR CODE HERE\n",
        "              - Call pack_padded_sequence on embs\n",
        "              - Feed embeddings and hidden state into the LSTM/GRU\n",
        "              - Call pad_packed_sequence on the output\n",
        "              - Feed output into a dense layer \n",
        "              - Remove the final prediction and reshape to match the loss function\n",
        "            \"\"\"\n",
        "            # BEGIN SOLUTION\n",
        "            embeds = pack_padded_sequence(embs,seq_lengths.to('cpu'), batch_first=True, enforce_sorted=False)\n",
        "            output, hidden = self.lstm_d(embeds, hidden)\n",
        "            \n",
        "            output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "            output = self.linear(output)\n",
        "            # END SOLUTION\n",
        "            output = output[:, : -1, :]\n",
        "            output = output.transpose(1, 2)\n",
        "            return output, hidden\n",
        "        else:\n",
        "            \"\"\"\n",
        "            YOUR CODE HERE\n",
        "              - Feed embeddings and hidden state into the LSTM/GRU\n",
        "              - Feed output into a dense layer \n",
        "            \"\"\"\n",
        "            # BEGIN SOLUTION\n",
        "            output, hidden = self.lstm_d(embs, hidden)\n",
        "            output = self.linear(output)\n",
        "            # END SOLUTION\n",
        "            return output, hidden\n",
        "\n",
        "    def get_embeddings(self, word_seqs, target_colors=None):\n",
        "        \"\"\"\n",
        "        Gets the input token representations. At present, these are\n",
        "        just taken directly from `self.embedding`, but `target_colors`\n",
        "        can be made available in case the user wants to subclass this\n",
        "        function to append these representations to each input token.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        word_seqs : torch.LongTensor\n",
        "            This is a padded sequence, dimension (m, k), where k is\n",
        "            the length of the longest sequence in the batch.\n",
        "\n",
        "        target_colors : torch.FloatTensor\n",
        "            Dimension (m, c), where m is the number of examples and\n",
        "            c is the dimensionality of the color representations.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.embedding(word_seqs)\n",
        "\n",
        "    @staticmethod\n",
        "    def _define_embedding(embedding, vocab_size, embed_dim, freeze_embedding):\n",
        "        if embedding is None:\n",
        "            emb = nn.Embedding(vocab_size, embed_dim)\n",
        "            emb.weight.requires_grad = not freeze_embedding\n",
        "            return emb\n",
        "        else:\n",
        "            embedding = torch.FloatTensor(embedding)\n",
        "            return nn.Embedding.from_pretrained(\n",
        "                embedding, freeze=freeze_embedding)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.349899Z",
          "iopub.execute_input": "2022-04-30T09:15:30.350178Z",
          "iopub.status.idle": "2022-04-30T09:15:30.367231Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.350145Z",
          "shell.execute_reply": "2022-04-30T09:15:30.366548Z"
        },
        "trusted": true,
        "id": "L4L0a2arnatQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        \"\"\"\n",
        "        This class knits the `Encoder` and `Decoder` into a single class\n",
        "        that serves as the model for `ContextualColorDescriber`. This is\n",
        "        largely a convenience: it means that `ContextualColorDescriber`\n",
        "        can use a single `model` argument, and it allows us to localize\n",
        "        the core computations in the `forward` method of this class.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        encoder : `Encoder`\n",
        "\n",
        "        decoder : `Decoder`\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, color_seqs, word_seqs, seq_lengths, hidden=None):\n",
        "        \"\"\"This is the core method for this module. It has a lot of\n",
        "        arguments mainly to make it easy to create subclasses of this\n",
        "        class that do interesting things without requiring modifications\n",
        "        to the `fit` method of `ContextualColorDescriber`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : torch.FloatTensor\n",
        "            Dimension (m, n, p), where m is the number of examples,\n",
        "            n is the number of colors in each context, and p is the\n",
        "            dimensionality of each color.\n",
        "\n",
        "        word_seqs : torch.LongTensor\n",
        "            Dimension (m, k), where m is the number of examples and k\n",
        "            is the length of all the (padded) sequences in the batch.\n",
        "\n",
        "        seq_lengths : torch.LongTensor or None\n",
        "            The true lengths of the sequences in `word_seqs`. If this\n",
        "            is None, then we are predicting new sequences, so we will\n",
        "            continue predicting until we hit a maximum length or we\n",
        "            generate STOP_SYMBOL.\n",
        "\n",
        "        hidden : torch.FloatTensor or None\n",
        "            The hidden representation for each of the m examples in this\n",
        "            batch. If this is None, we are predicting new sequences\n",
        "            and so the hidden representation is computed for each timestep\n",
        "            during decoding.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output : torch.FloatTensor\n",
        "            Dimension (m, k, c), where m is the number of examples, k\n",
        "            is the length of the sequences in this batch, and c is the\n",
        "            number of classes (the size of the vocabulary).\n",
        "\n",
        "        hidden : torch.FloatTensor\n",
        "            Dimension (m, h) where m is the number of examples and h is\n",
        "            the dimensionality of the hidden representations of the model.\n",
        "            This value is returned only when the model is in eval mode.\n",
        "\n",
        "        \"\"\"\n",
        "        if hidden is None:\n",
        "            hidden = self.encoder(color_seqs)\n",
        "        output, hidden = self.decoder(\n",
        "            word_seqs, seq_lengths=seq_lengths, hidden=hidden)\n",
        "        if self.training:\n",
        "            return output\n",
        "        else:\n",
        "            return output, hidden"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.368531Z",
          "iopub.execute_input": "2022-04-30T09:15:30.369059Z",
          "iopub.status.idle": "2022-04-30T09:15:30.379691Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.369025Z",
          "shell.execute_reply": "2022-04-30T09:15:30.378991Z"
        },
        "trusted": true,
        "id": "Si-agoXknatQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference and Evaluation\n",
        "\n",
        "Please read the following code closely, as it defines our evaluation criteria. Because exact match with our reference annotations is too stringent a criteria, we'll use a word-overlap metric (unigram BLEU). We also use a [pragmatic listener-based evaluation](https://arxiv.org/abs/1909.07290) defined as follows:\n",
        "\n",
        "$$\n",
        "\\operatorname{L}(\\text{utterance}, C) = \\underset{c \\in C}{\\mathrm{argmax}}\\,\\operatorname{S}(\\text{utterance} \\mid c)\n",
        "$$\n",
        "\n",
        "where $c \\in C$ is a color in the set of colors $C$ and $S$ is the speaker model defined above. This is a fundamentally *pragmatic* evaluation criteria because it models speaker's performance in terms of whether or not a listener could accurately infer their intended meaning. For more information about computational pragmatics, see [Goodman & Frank (2016)](https://www.sciencedirect.com/science/article/pii/S136466131630122X?casa_token=KQaBwc3jIDAAAAAA:hmyhXA3rxE7qRGILgoSS9erA17tPI7Az_6h2_TN1UmbuMemWKDJQxR6PaLkJ4woj_4zSg9ePN_I). Note that many other approaches to listener-based evaluation may use a cross-talk setting in which the listener is a separate agent trained on a different subset of data. As part of the experimentation for your report, you are welcome to explore this direction by building a separate listener agent.\n",
        "\n",
        "Because the pragmatic listener is part of our evaluation criteria, we won't ask you to implement it. We will however ask that you write the inner loop of thet `predict` function, which calls `self.model` at each step of decoding."
      ],
      "metadata": {
        "id": "mFWKBO5BnatR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContextualColorDescriber(TorchModelBase):\n",
        "    def __init__(self,\n",
        "            vocab,\n",
        "            embedding=None,\n",
        "            embed_dim=50,\n",
        "            hidden_dim=50,\n",
        "            freeze_embedding=False,\n",
        "            **base_kwargs):\n",
        "        \"\"\"\n",
        "        The primary interface to modeling contextual colors datasets.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        vocab : list of str\n",
        "            This should be the vocabulary. It needs to be aligned with\n",
        "            `embedding` in the sense that the ith element of vocab\n",
        "            should be represented by the ith row of `embedding`.\n",
        "            \n",
        "        embedding : np.array or None\n",
        "            Each row represents a word in `vocab`, as described above.\n",
        "\n",
        "        embed_dim : int\n",
        "            Dimensionality for the initial embeddings. This is ignored\n",
        "            if `embedding` is not None, as a specified value there\n",
        "            determines this value.\n",
        "\n",
        "        hidden_dim : int\n",
        "            Dimensionality of the hidden layer.\n",
        "\n",
        "        freeze_embedding : bool\n",
        "            If True, the embedding will be updated during training. If\n",
        "            False, the embedding will be frozen. This parameter applies\n",
        "            to both randomly initialized and pretrained embeddings.\n",
        "\n",
        "        **base_kwargs\n",
        "            For details, see `torch_model_base.py`.\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        vocab_size : int\n",
        "\n",
        "        word2index : dict\n",
        "            A look-up from vocab items to their indices.\n",
        "\n",
        "        index2word : dict\n",
        "            A look-up for indices to vocab items.\n",
        "\n",
        "        output_dim : int\n",
        "            Same as `vocab_size`.\n",
        "\n",
        "        start_index : int\n",
        "            Index of START_SYMBOL in `self.vocab`.\n",
        "\n",
        "        end_index : int\n",
        "            Index of END_SYMBOL in `self.vocab`.\n",
        "\n",
        "        unk_index : int\n",
        "            Index of UNK_SYMBOL in `self.vocab`.\n",
        "\n",
        "        loss: nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "        self.params: list\n",
        "            Extends TorchModelBase.params with names for all of the\n",
        "            arguments for this class to support tuning of these values\n",
        "            using `sklearn.model_selection` tools.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__(**base_kwargs)\n",
        "        self.vocab = vocab\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = embedding\n",
        "        self.freeze_embedding = freeze_embedding\n",
        "        self.vocab_size = len(vocab)\n",
        "        self.word2index = dict(zip(self.vocab, range(self.vocab_size)))\n",
        "        self.index2word = dict(zip(range(self.vocab_size), self.vocab))\n",
        "        self.embed_dim = embed_dim\n",
        "        self.output_dim = self.vocab_size\n",
        "        self.start_index = self.vocab.index(START_SYMBOL)\n",
        "        self.end_index = self.vocab.index(END_SYMBOL)\n",
        "        self.unk_index = self.vocab.index(UNK_SYMBOL)\n",
        "        self.params += ['hidden_dim', 'embed_dim', 'embedding', 'freeze_embedding']\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def build_dataset(self, color_seqs, word_seqs):\n",
        "        \"\"\"\n",
        "\n",
        "        Create a dataset from a list of color contexts and\n",
        "        associated utterances.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        color_seqs : list of lists of color representations\n",
        "            We assume that each context has the same number of colors,\n",
        "            each with the same shape.\n",
        "\n",
        "        word_seqs : list of lists of utterances\n",
        "            A tokenized list of words. This method uses `self.word2index`\n",
        "            to turn this into a list of lists of indices.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        ColorDataset\n",
        "\n",
        "        \"\"\"\n",
        "        self.color_dim = len(color_seqs[0][0])\n",
        "        word_seqs = [[self.word2index.get(w, self.unk_index) for w in seq]\n",
        "                     for seq in word_seqs]\n",
        "        ex_lengths = [len(seq) for seq in word_seqs]\n",
        "        return ColorDataset(color_seqs, word_seqs, ex_lengths)\n",
        "\n",
        "    def build_graph(self):\n",
        "        \"\"\"\n",
        "        The core computation graph. This method is called by `fit` to set\n",
        "        the `self.model` attribute.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `EncoderDecoder` built from `Encoder` and `Decoder`\n",
        "\n",
        "        \"\"\"\n",
        "        encoder = Encoder(\n",
        "            color_dim=self.color_dim,\n",
        "            hidden_dim=self.hidden_dim)\n",
        "\n",
        "        decoder = Decoder(\n",
        "            vocab_size=self.vocab_size,\n",
        "            embed_dim=self.embed_dim,\n",
        "            embedding=self.embedding,\n",
        "            hidden_dim=self.hidden_dim,\n",
        "            freeze_embedding=self.freeze_embedding)\n",
        "\n",
        "        self.embed_dim = decoder.embed_dim\n",
        "        return EncoderDecoder(encoder, decoder)\n",
        "\n",
        "    def predict(self, color_seqs, max_length=20, device=None):\n",
        "        \"\"\"\n",
        "        Predict new sequences based on the color contexts in\n",
        "        `color_seqs`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : list of lists of lists of floats, or np.array\n",
        "            Dimension (m, n, p) where m is the number of examples, n is\n",
        "            the number of colors in each context, and p is the length\n",
        "            of the color representations.\n",
        "\n",
        "        max_length : int\n",
        "            Length of the longest sequences to create.\n",
        "\n",
        "        device: str or None\n",
        "            Allows the user to temporarily change the device used\n",
        "            during prediction. This is useful if predictions require a\n",
        "            lot of memory and so are better done on the CPU. After\n",
        "            prediction is done, the model is returned to `self.device`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list of str\n",
        "\n",
        "        \"\"\"\n",
        "        device = self.device if device is None else torch.device(device)\n",
        "        color_seqs = torch.FloatTensor(color_seqs)\n",
        "        color_seqs = color_seqs.to(device)\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "        preds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Get the hidden representations from the color contexts:\n",
        "            hidden = self.model.encoder(color_seqs)\n",
        "\n",
        "            # Start with START_SYMBOL for all examples:\n",
        "            decoder_input = [[self.start_index]] * len(color_seqs)\n",
        "            decoder_input = torch.LongTensor(decoder_input)\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            preds.append(decoder_input)\n",
        "\n",
        "            \n",
        "            \"\"\"\n",
        "            YOUR CODE HERE\n",
        "              - Iterate until max_length is reached\n",
        "              - At each iteration, feed your hidden states into self.model\n",
        "              - Take the argmax of your output to get the highest probability token\n",
        "              - Append this token to preds, and update your decoder_input\n",
        "            \"\"\"\n",
        "            # BEGIN SOLUTION\n",
        "            # Now move through the remaiming timesteps using the\n",
        "            # previous timestep to predict the next one:\n",
        "            for i in range(max_length):\n",
        "              output, hidden = self.model.decoder(decoder_input, hidden=hidden, seq_lengths=None)\n",
        "              output = torch.argmax(output, dim=-1)\n",
        "              preds.append(output)\n",
        "              decoder_input = output\n",
        "            # END SOLUTION\n",
        "\n",
        "        # Convert all the predictions from indices to elements of\n",
        "        # `self.vocab`:\n",
        "        preds = torch.cat(preds, axis=1)\n",
        "        preds = [self._convert_predictions(p) for p in preds]\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        return preds\n",
        "\n",
        "    def _convert_predictions(self, pred):\n",
        "        rep = []\n",
        "        for i in pred:\n",
        "            i = i.item()\n",
        "            rep.append(self.index2word[i])\n",
        "            if i == self.end_index:\n",
        "                return rep\n",
        "        return rep\n",
        "\n",
        "    def predict_proba(self, color_seqs, word_seqs, device=None):\n",
        "        \"\"\"\n",
        "        Calculate the predicted probabilities of the sequences in\n",
        "        `word_seqs` given the color contexts in `color_seqs`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : list of lists of lists of floats, or np.array\n",
        "            Dimension (m, n, p) where m is the number of examples, n is\n",
        "            the number of colors in each context, and p is the length\n",
        "            of the color representations.\n",
        "\n",
        "        word_seqs : list of list of int\n",
        "            Dimension m, the number of examples. The length of each\n",
        "            sequence can vary.\n",
        "\n",
        "        device: str or None\n",
        "            Allows the user to temporarily change the device used\n",
        "            during prediction. This is useful if predictions require a\n",
        "            lot of memory and so are better done on the CPU. After\n",
        "            prediction is done, the model is returned to `self.device`.\n",
        "\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list of lists of predicted probabilities. In other words,\n",
        "        for each example, at each timestep, there is a probability\n",
        "        distribution over the entire vocabulary.\n",
        "\n",
        "        \"\"\"\n",
        "        device = self.device if device is None else torch.device(device)\n",
        "        dataset = self.build_dataset(color_seqs, word_seqs)\n",
        "        dataloader = self._build_dataloader(dataset, shuffle=False)\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "        softmax = nn.Softmax(dim=2)\n",
        "        start_probs = np.zeros(self.vocab_size)\n",
        "        start_probs[self.start_index] = 1.0\n",
        "        all_probs = []\n",
        "        with torch.no_grad():\n",
        "            for batch_colors, batch_words, batch_lens, targets in dataloader:\n",
        "                batch_colors = batch_colors.to(device)\n",
        "                batch_words = batch_words.to(device)\n",
        "                batch_lens = batch_lens.to(device)\n",
        "\n",
        "                output, _ = self.model(\n",
        "                    color_seqs=batch_colors,\n",
        "                    word_seqs=batch_words,\n",
        "                    seq_lengths=batch_lens)\n",
        "\n",
        "                probs = softmax(output)\n",
        "                probs = probs.cpu().numpy()\n",
        "                probs = np.insert(probs, 0, start_probs, axis=1)\n",
        "                all_probs += [p[: n] for p, n in zip(probs, batch_lens)]\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        return all_probs\n",
        "\n",
        "    def perplexities(self, color_seqs, word_seqs, device=None):\n",
        "        \"\"\"\n",
        "        Compute the perplexity of each sequence in `word_seqs`\n",
        "        given `color_seqs`. For a sequence of conditional probabilities\n",
        "        p1, p2, ..., pN, the perplexity is calculated as\n",
        "\n",
        "        (p1 * p2 * ... * pN)**(-1/N)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : list of lists of floats, or np.array\n",
        "            Dimension (m, n, p) where m is the number of examples, n is\n",
        "            the number of colors in each context, and p is the length\n",
        "            of the color representations.\n",
        "\n",
        "        word_seqs : list of list of int\n",
        "            Dimension m, the number of examples, and the length of\n",
        "            each sequence can vary.\n",
        "\n",
        "        device: str or None\n",
        "            Allows the user to temporarily change the device used\n",
        "            during prediction. This is useful if predictions require a\n",
        "            lot of memory and so are better done on the CPU. After\n",
        "            prediction is done, the model is returned to `self.device`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list of float\n",
        "\n",
        "        \"\"\"\n",
        "        probs = self.predict_proba(color_seqs, word_seqs, device=device)\n",
        "        scores = []\n",
        "        for pred, seq in zip(probs, word_seqs):\n",
        "            # Get the probabilities corresponding to the path `seq`:\n",
        "            s = np.array([t[self.word2index.get(w, self.unk_index)]\n",
        "                         for t, w in zip(pred, seq)])\n",
        "            scores.append(s)\n",
        "        perp = [np.prod(s)**(-1/len(s)) for s in scores]\n",
        "        return perp\n",
        "\n",
        "    def listener_predict_one(self, context, seq, device=None):\n",
        "        context = np.array(context)\n",
        "        n_colors = len(context)\n",
        "\n",
        "        # Get all possible context orders:\n",
        "        indices = list(range(n_colors))\n",
        "        orders = [list(x) for x in itertools.permutations(indices)]\n",
        "\n",
        "        # Shuffle the context order list so that the true context\n",
        "        # is in a random place in the list:\n",
        "        random.shuffle(orders)\n",
        "\n",
        "        # All contexts as color sequences:\n",
        "        contexts = [context[x] for x in orders]\n",
        "\n",
        "        # Repeat the single utterance the needed number of times:\n",
        "        seqs = [seq] * len(contexts)\n",
        "\n",
        "        # All perplexities:\n",
        "        perps = self.perplexities(contexts, seqs, device=device)\n",
        "\n",
        "        # Ranking, using `order_indices` rather than colors and\n",
        "        # index sequences to avoid sorting errors from some versions\n",
        "        # of Python:\n",
        "        order_indices = range(len(orders))\n",
        "        ranking = sorted(zip(perps, order_indices))\n",
        "\n",
        "        # Return the minimum perplexity, the chosen color, and the\n",
        "        # index of the chosen color in the original context:\n",
        "        min_perp, order_index = ranking[0]\n",
        "        pred_color = contexts[order_index][-1]\n",
        "        pred_index = orders[order_index][-1]\n",
        "        return min_perp, pred_color, pred_index\n",
        "\n",
        "    def listener_predictions(self, color_seqs, word_seqs, device=None):\n",
        "        \"\"\"\n",
        "        Compute the listener predictions of the model for each example.\n",
        "        For the ith example, this is defined as\n",
        "\n",
        "        prediction = max_{c in C_i} P(word_seq[i] | c)\n",
        "\n",
        "        where C_i is every possible permutation of the three colors in\n",
        "        color_seqs[i]. We take the model's prediction to be correct\n",
        "        if it chooses a c in which the target is in the privileged final\n",
        "        position in the color sequence. (There are two such c's, since\n",
        "        the distractors can be in two orders; we give full credit if one\n",
        "        of these two c's is chosen.)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : list of lists of list of floats, or np.array\n",
        "            Dimension (m, n, p) where m is the number of examples, n is\n",
        "            the number of colors in each context, and p is the length\n",
        "            of the color representations.\n",
        "\n",
        "        word_seqs : list of list of int\n",
        "            Dimension m, the number of examples, and the length of\n",
        "            each sequence can vary.\n",
        "\n",
        "        device: str or None\n",
        "            Allows the user to temporarily change the device used\n",
        "            during prediction. This is useful if predictions require a\n",
        "            lot of memory and so are better done on the CPU. After\n",
        "            prediction is done, the model is returned to `self.device`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple of lists, the first member giving the gold target indices\n",
        "        and the second giving the predicted target indices.\n",
        "\n",
        "        \"\"\"\n",
        "        gold = []\n",
        "        predicted = []\n",
        "        correct = 0\n",
        "        for color_seq, word_seq in zip(color_seqs, word_seqs):\n",
        "            target_index = len(color_seq) - 1\n",
        "            min_perp, pred, pred_index = self.listener_predict_one(\n",
        "                color_seq, word_seq, device=device)\n",
        "            gold.append(target_index)\n",
        "            predicted.append(pred_index)\n",
        "        return gold, predicted\n",
        "\n",
        "    def listener_accuracy(self, color_seqs, word_seqs, device=None):\n",
        "        \"\"\"\n",
        "        Returns the listener accuracy as calculated based on values\n",
        "        returns by `listener_predictions`.\n",
        "\n",
        "        \"\"\"\n",
        "        gold, predicted = self.listener_predictions(\n",
        "            color_seqs, word_seqs, device=device)\n",
        "        return accuracy_score(gold, predicted)\n",
        "\n",
        "    def score(self, color_seqs, word_seqs, device=None):\n",
        "        \"\"\"\n",
        "        Alias for `listener_accuracy`. This method is included to\n",
        "        make it easier to use sklearn cross-validators, which expect\n",
        "        a method called `score`.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.listener_accuracy(color_seqs, word_seqs, device=device)\n",
        "\n",
        "    def corpus_bleu(self, color_seqs, word_seqs):\n",
        "        \"\"\"\n",
        "        Calculate the corpus BLEU score achieved by `model` with respect\n",
        "        to `color_seqs` and `word_seqs`, using just unigrams.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : list of lists of lists of floats, or np.array\n",
        "            Dimension (m, n, p) where m is the number of examples, n is\n",
        "            the number of colors in each context, and p is the length\n",
        "            of the color representations.\n",
        "\n",
        "        word_seqs : list of lists of utterances\n",
        "            A tokenized list of words.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple consisting of the bleu score (float) and the predictions\n",
        "        as a list of lists of tokens\n",
        "\n",
        "        \"\"\"\n",
        "        # Ideally, we would have multiple references for each context,\n",
        "        # but alas we have only one:\n",
        "        refs = [[seq] for seq in word_seqs]\n",
        "\n",
        "        # Predict some utterances:\n",
        "        preds = self.predict(color_seqs)\n",
        "\n",
        "        # Calculate a unigrams-only BLEU score:\n",
        "        bleu = nltk.translate.bleu_score.corpus_bleu(\n",
        "            refs, preds, weights=(1, ))\n",
        "\n",
        "        return bleu, preds\n",
        "\n",
        "    def evaluate(self, color_seqs, word_seqs, device=None):\n",
        "        \"\"\"\n",
        "        Full evaluation for the bake-off. Uses `listener_accuracy`\n",
        "        and colors_corpus_bleu`.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        color_seqs : list of lists of lists of floats, or np.array\n",
        "            Dimension (m, n, p) where m is the number of examples, n is\n",
        "            the number of colors in each context, and p is the length\n",
        "            of the color representations.\n",
        "\n",
        "        word_seqs : list of lists of utterances\n",
        "            A tokenized list of words.\n",
        "\n",
        "        device: str or None\n",
        "            Allows the user to temporarily change the device used\n",
        "            during prediction. This is useful if predictions require a\n",
        "            lot of memory and so are better done on the CPU. After\n",
        "            prediction is done, the model is returned to `self.device`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict, {\n",
        "            \"listener_accuracy\": float,\n",
        "            \"corpus_bleu\": float,\n",
        "            \"target_index\": list of int,\n",
        "            \"predicted_index\": list of int}\n",
        "\n",
        "        \"\"\"\n",
        "        gold, predicted = self.listener_predictions(\n",
        "            color_seqs, word_seqs, device=device)\n",
        "        acc = accuracy_score(gold, predicted)\n",
        "        bleu, pred_utt = self.corpus_bleu(color_seqs, word_seqs)\n",
        "        return {\n",
        "            \"listener_accuracy\": acc,\n",
        "            \"corpus_bleu\": bleu,\n",
        "            \"target_index\": gold,\n",
        "            \"predicted_index\": predicted,\n",
        "            \"predicted_utterance\": pred_utt}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.381221Z",
          "iopub.execute_input": "2022-04-30T09:15:30.381621Z",
          "iopub.status.idle": "2022-04-30T09:15:30.428297Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.381587Z",
          "shell.execute_reply": "2022-04-30T09:15:30.427579Z"
        },
        "trusted": true,
        "id": "SZgyeUfXnatR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimenting with Toy Data\n",
        "\n",
        "We'll use the following code which generates a toy dataset to determine whether or not your encoder-decoder model is working correctly. You should expect to achieve perfect exact match, listener accuracy, and a 1.0 BLEU on this dataset:"
      ],
      "metadata": {
        "id": "T3DKnL4HnatT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_example_dataset(group_size=100, vec_dim=2):\n",
        "    \"\"\"\n",
        "    Creates simple datasets in which the inputs are three-vector\n",
        "    sequences and the outputs are simple character sequences, with\n",
        "    the range of values in the final vector in the input determining\n",
        "    the output sequence. For example, a single input/output pair\n",
        "    will look like this:\n",
        "\n",
        "    [[0.44, 0.51], [0.87, 0.89], [0.1, 0.2]],  ['<s>', 'A', '</s>']\n",
        "\n",
        "    The sequences are meaningless, as are their lengths (which were\n",
        "    chosen only to be different from each other).\n",
        "\n",
        "    \"\"\"\n",
        "    groups = ((0.0, 0.2), (0.4, 0.6), (0.8, 1.0))\n",
        "    vocab = ['<s>', '</s>', 'A', 'B', '$UNK']\n",
        "    seqs = [\n",
        "        ['<s>', 'A', '</s>'],\n",
        "        ['<s>', 'A', 'B', '</s>'],\n",
        "        ['<s>', 'B', 'A', 'B', 'A', '</s>']]\n",
        "    color_seqs = []\n",
        "    word_seqs = []\n",
        "    for i, ((l, u), seq) in enumerate(zip(groups, seqs)):\n",
        "        dis_indices = list(range(len(groups)))\n",
        "        dis_indices.remove(i)\n",
        "        random.shuffle(dis_indices)\n",
        "        disl1, disu1 = groups[dis_indices[0]]\n",
        "        disl2, disu2 = groups[dis_indices[1]]\n",
        "        for _ in range(group_size):\n",
        "            target = randvec(vec_dim, l, u)\n",
        "            dis1 = randvec(vec_dim, disl1, disu1)\n",
        "            dis2 = randvec(vec_dim, disl2, disu2)\n",
        "            context = [dis1, dis2, target]\n",
        "            color_seqs.append(context)\n",
        "        word_seqs += [seq for _ in range(group_size)]\n",
        "    return color_seqs, word_seqs, vocab"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.430594Z",
          "iopub.execute_input": "2022-04-30T09:15:30.431034Z",
          "iopub.status.idle": "2022-04-30T09:15:30.441298Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.430998Z",
          "shell.execute_reply": "2022-04-30T09:15:30.440561Z"
        },
        "trusted": true,
        "id": "QWQMnUKqnatT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model should train in just a few seconds:"
      ],
      "metadata": {
        "id": "KgX0xHoFnatU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toy_color_seqs, toy_word_seqs, toy_vocab = create_example_dataset(group_size=50, vec_dim=2)\n",
        "toy_color_seqs_train, toy_color_seqs_test, toy_word_seqs_train, toy_word_seqs_test = \\\n",
        "    train_test_split(toy_color_seqs, toy_word_seqs)\n",
        "\n",
        "toy_mod = ContextualColorDescriber(toy_vocab, max_iter=200)\n",
        "_ = toy_mod.fit(toy_color_seqs_train, toy_word_seqs_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:30.442604Z",
          "iopub.execute_input": "2022-04-30T09:15:30.442871Z",
          "iopub.status.idle": "2022-04-30T09:15:31.87216Z",
          "shell.execute_reply.started": "2022-04-30T09:15:30.442836Z",
          "shell.execute_reply": "2022-04-30T09:15:31.871487Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go9OvFnfnatU",
        "outputId": "36136092-c0c3-4ebd-be31-8bcd86510fc4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
            "Finished epoch 200 of 200; error is 0.25743505358695984"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_preds = toy_mod.predict(toy_color_seqs_test)\n",
        "toy_correct = sum(1 for x, p in zip(toy_word_seqs_test, toy_preds) if x == p)\n",
        "listener_acc = toy_mod.listener_accuracy(toy_color_seqs_test, toy_word_seqs_test)\n",
        "bleu_score, _ = toy_mod.corpus_bleu(toy_color_seqs_test, toy_word_seqs_test)\n",
        "      \n",
        "print(\"Exact match (toy data): {}\".format(toy_correct / len(toy_word_seqs_test)))\n",
        "print(\"Listener accuracy (toy data): {}\".format(listener_acc))\n",
        "print(\"BLEU (toy data): {}\".format(bleu_score))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:31.874809Z",
          "iopub.execute_input": "2022-04-30T09:15:31.875005Z",
          "iopub.status.idle": "2022-04-30T09:15:32.000736Z",
          "shell.execute_reply.started": "2022-04-30T09:15:31.874981Z",
          "shell.execute_reply": "2022-04-30T09:15:32.000045Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X5xdkmDnatU",
        "outputId": "36ce50bb-31b8-4edd-a4f0-d720cbb1851f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact match (toy data): 1.0\n",
            "Listener accuracy (toy data): 1.0\n",
            "BLEU (toy data): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model Evaluation\n",
        "\n",
        "Next, we'll evaluate our baseline model on a subset of the Colors in Context dataset. We'll use a split of the data consisting of only two-word utterances. This will allow us to train models relatively quickly, usually about 1-2 minutes each. You should expect the baseline model to perform relatively poorly, with a listener accuracy only slightly above random chance."
      ],
      "metadata": {
        "id": "9DsKanTTnatU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_corpus = ColorsCorpusReader(\"colors.csv\", word_count=2)\n",
        "dev_examples = list(dev_corpus.read())\n",
        "print(\"Number of evaluation examples: {}\".format(len(dev_examples)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:32.00261Z",
          "iopub.execute_input": "2022-04-30T09:15:32.002875Z",
          "iopub.status.idle": "2022-04-30T09:15:33.843967Z",
          "shell.execute_reply.started": "2022-04-30T09:15:32.00284Z",
          "shell.execute_reply": "2022-04-30T09:15:33.843208Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpBzgEG2natU",
        "outputId": "07d6804b-0eae-4dff-a600-00fe8d943605"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of evaluation examples: 8831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_cols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples])\n",
        "dev_word_seqs = [[START_SYMBOL] + text.split() + [END_SYMBOL] for text in dev_texts]\n",
        "dev_cols_train, dev_cols_test, dev_word_seqs_train, dev_word_seqs_test = train_test_split(dev_cols, dev_word_seqs)\n",
        "\n",
        "dev_vocab = sorted({w for toks in dev_word_seqs_train for w in toks})\n",
        "dev_vocab += [UNK_SYMBOL]\n",
        "print(\"Vocab size: {}\".format(len(dev_vocab)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:33.845267Z",
          "iopub.execute_input": "2022-04-30T09:15:33.84566Z",
          "iopub.status.idle": "2022-04-30T09:15:33.928427Z",
          "shell.execute_reply.started": "2022-04-30T09:15:33.845622Z",
          "shell.execute_reply": "2022-04-30T09:15:33.927614Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcepRnWKnatV",
        "outputId": "46514805-63cd-4cbd-e8b7-1f5d17d37332"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 1122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code should take slightly longer than a minute to run:"
      ],
      "metadata": {
        "id": "hN-lYUu7natV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mod = ContextualColorDescriber(\n",
        "    dev_vocab,\n",
        "    embed_dim=10,\n",
        "    hidden_dim=10,\n",
        "    early_stopping=True)\n",
        "\n",
        "%time _ = dev_mod.fit(dev_cols_train, dev_word_seqs_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-30T09:15:33.929848Z",
          "iopub.execute_input": "2022-04-30T09:15:33.930104Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUT7v-junatV",
        "outputId": "cb108d63-9b19-49ef-cc14-775ad2b71342"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 38.56268930435181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 38 s, sys: 116 ms, total: 38.1 s\n",
            "Wall time: 38.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mod_eval = dev_mod.evaluate(dev_cols_test, dev_word_seqs_test)\n",
        "print(\"Listener accuracy (baseline): {}\".format(dev_mod_eval['listener_accuracy']))\n",
        "print(\"BLEU (baseline): {}\".format(dev_mod_eval['corpus_bleu']))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzHhuaLJnatV",
        "outputId": "837186a2-f77c-4c3e-ae15-81db9ddd952c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listener accuracy (baseline): 0.3129528985507246\n",
            "BLEU (baseline): 0.04949534161490683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our baseline model achieved a listener accuracy of 0.36 and a corpus BLEU of 0.05, which means it was mostly producing empty strings. You may experience some slight variance here, but overall the performance should be quite weak.\n",
        "\n",
        "## Improved Model\n",
        "\n",
        "To improve the model, we'll focus on two extensions to our baseline model: (1) improving the tokenizer and (2) improving the input representation of color data. Although relatively straightforward, these modifications should give you a taste of some of the challenges of multimodal NLP.\n",
        "\n",
        "### Modified Tokenizer\n",
        "\n",
        "For many grounded language learning tasks, small vocabularies lead to better performance. Intuitively, this might be because most words don't have a visual analogue, so models tend to perform better with less word types; this also occurs because many grounded language learning datasets are especially small, and collapsing different forms of the same word into one can improve learning.\n",
        "\n",
        "In this section, we'll ask you to improve the tokenizer as described in the [Colors in Context](https://arxiv.org/pdf/1703.10186.pdf) paper. You are welcome to experiment with a few different configurations, and there's not obviously a best solution, but you should aim to significantly reduce the vocabulary size. Our reference implementation has a vocabulary size of 194 words. You may also wish to use a stemmer or lemmatizer, as discussed in the paper; you can find imports for these in the first cell of this notebook."
      ],
      "metadata": {
        "id": "xgrAWH4snatW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "  - You may wish to instantiate a lemmatizer or stemmer for your tokenizer\n",
        "  - See the NLTK documentation: https://www.nltk.org\n",
        "  - You may also wish to define a Counter() in order to <UNK> common words later on\n",
        "\"\"\" \n",
        "# BEGIN SOLUTION\n",
        "import re\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "nltk.download('wordnet')\n",
        "lmtzr = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "po=[]\n",
        "# END SOLUTION\n",
        "\n",
        "def tokenize_example(s):\n",
        "    \"\"\"\n",
        "    YOUR CODE HERE\n",
        "      - Lowercase and remove punctuation\n",
        "      - Remove rare words \n",
        "      - Possibly remove suffixes using a stemmer/lemmatizer\n",
        "    \"\"\"\n",
        "    words = s.split()\n",
        "    # BEGIN SOLUTION\n",
        "    words = [re.sub(r'[^\\w\\s]', '', word).lower() for word in words]\n",
        "    \n",
        "    \n",
        "    words = [lmtzr.lemmatize(word) for word in words]\n",
        "    words = [ps.stem(word) for word in words]\n",
        "    if words and '' not in words:\n",
        "      po.append(pos_tag(words))\n",
        "      words = [word for word, pos in pos_tag(words) if pos in ['JJ','NN', 'JJS']] #add or remove tags here\n",
        "    # END SOLUTION\n",
        "    return [START_SYMBOL] + words + [END_SYMBOL]\n",
        "\n",
        "'''\n",
        "def test_tokenize_example(func):\n",
        "    s = \"A test string\"\n",
        "    result = func(s)\n",
        "    assert all(isinstance(tok, str) for tok in result), \\\n",
        "        \"The tokenizer must return a list of strings.\"\n",
        "    assert result[0] == START_SYMBOL, \\\n",
        "        \"The tokenizer must add START_SYMBOL as the first token.\"\n",
        "    assert result[-1] == END_SYMBOL, \\\n",
        "        \"The tokenizer must add END_SYMBOL as the final token.\"\n",
        "    \n",
        "test_tokenize_example(tokenize_example)'''"
      ],
      "metadata": {
        "trusted": true,
        "id": "TEujjIIgnatW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7c51e908-2d1d-4818-e9e3-c0c202bbf6cf"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef test_tokenize_example(func):\\n    s = \"A test string\"\\n    result = func(s)\\n    assert all(isinstance(tok, str) for tok in result),         \"The tokenizer must return a list of strings.\"\\n    assert result[0] == START_SYMBOL,         \"The tokenizer must add START_SYMBOL as the first token.\"\\n    assert result[-1] == END_SYMBOL,         \"The tokenizer must add END_SYMBOL as the final token.\"\\n    \\ntest_tokenize_example(tokenize_example)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "dev_rawcols, dev_texts, dev_cons = zip(*[[ex.colors, ex.contents, ex.condition] for ex in dev_examples])\n",
        "dev_rawcols_train, dev_rawcols_test, dev_texts_train, dev_texts_test, dev_cons_train, dev_cons_test = train_test_split(dev_rawcols, dev_texts, dev_cons)\n",
        "\n",
        "dev_seqs_train = [tokenize_example(s) for s in dev_texts_train]\n",
        "dev_seqs_test = [tokenize_example(s) for s in dev_texts_test]\n",
        "\n",
        "counter = Counter(word for i in dev_seqs_train for word in i)\n",
        "counter = {word:counter[word] for word in counter if counter[word]>5 and len(word)>2}\n",
        "\n",
        "dev_vocab = sorted({toks for toks,count in counter.items()})\n",
        "dev_vocab += [UNK_SYMBOL]\n",
        "print(dev_vocab)\n",
        "\n",
        "print(\"Vocab size: {}\".format(len(dev_vocab)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "x1sXBzernatW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad362d3-1472-4592-ac8f-01c51937e26b"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "['</s>', '<s>', 'aqua', 'armi', 'babi', 'barney', 'beig', 'blue', 'blueish', 'bluer', 'bluest', 'bluish', 'bold', 'bore', 'box', 'boy', 'brighest', 'bright', 'brighter', 'brightest', 'brite', 'brown', 'brownish', 'burnt', 'caca', 'camo', 'choos', 'color', 'dark', 'darker', 'darkest', 'day', 'deep', 'deeper', 'drab', 'drabest', 'dull', 'duller', 'dullest', 'dusti', 'eggplant', 'fade', 'fluoresc', 'forest', 'girl', 'gold', 'good', 'grape', 'grass', 'gray', 'grayer', 'grayest', 'grayish', 'green', 'greener', 'greenest', 'greenish', 'grey', 'greyish', 'hot', 'hue', 'job', 'khaki', 'kinda', 'lavend', 'leaf', 'least', 'light', 'lighter', 'lightest', 'lime', 'lite', 'lol', 'look', 'magenta', 'mauv', 'medium', 'middl', 'militari', 'mint', 'more', 'most', 'mustard', 'mute', 'navi', 'neon', 'neutral', 'nice', 'normal', 'not', 'ocean', 'oliv', 'one', 'orang', 'orangish', 'pale', 'paler', 'pastel', 'pea', 'pink', 'pinki', 'pinkish', 'pinkpurpl', 'problem', 'puke', 'pure', 'purp', 'purpl', 'purpleish', 'purpley', 'purpli', 'purplish', 'red', 'reddish', 'redish', 'regular', 'royal', 'sage', 'salmon', 'same', 'sand', 'sea', 'seafoam', 'shade', 'sky', 'slate', 'sorri', 'squar', 'stormi', 'tan', 'tanish', 'teal', 'thank', 'the', 'tint', 'true', 'turquois', 'veri', 'vibrant', 'violet', 'water', 'watermelon', 'work', 'worri', 'yellow', 'yellowgreen', 'yellowish', '$UNK']\n",
            "Vocab size: 148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_examples[0].condition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2HHQVYGx9jyx",
        "outputId": "d066f8d7-a82c-4afb-b31c-37e5eef90483"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'close'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improved Visual Representations\n",
        "\n",
        "Finally, we'll ask you to convert the colors to a different representational format before feeding them into the model. Colors are currently in normalized HLS format, but you may wish to use the Fourier transform method in the paper to convert them into a 54-dimensional representation. You're welcome to experiment with other color representations as well, but some modifications to the following code will be necessary to achieve high performance. Note that if you're planning to use the Fourier method, you'll need to convert from HLS to HSV format (which you can do using the `colorsys` package). You can also use the `cmath` package to get the real and imaginary parts of a complex number; the Fourier method described in the paper will result in a 27 complex-valued numbers, which may be split into their real and imaginary parts and concatenated together to form a 54-dimensional representation."
      ],
      "metadata": {
        "id": "DFVtXkfynatW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "yZ21KN1N8YYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def represent_color_context(colors):\n",
        "    return [represent_color(color) for color in colors]\n",
        "def represent_color(color):\n",
        "    \n",
        "    \n",
        "    # BEGIN SOLUTION\n",
        "\n",
        "    h, s, v = colorsys.rgb_to_hsv(*colorsys.hls_to_rgb(*color))\n",
        "    fourier = [] #np.zeros(54)\n",
        "    for j in range(3):\n",
        "      for k in range(3):\n",
        "        for l in range(3):\n",
        "          f = np.exp(-2*np.pi*1j *(j*h + k*s + l*v))\n",
        "          f = [np.real(f), np.imag(f)] #all real, all imaginary does not work\n",
        "          fourier.extend(f)\n",
        "    return fourier\n",
        "    # END SOLUTION\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def test_represent_color_context(func):\n",
        "    \"\"\"`func` should be `represent_color_context`\"\"\"\n",
        "    example = [\n",
        "        [0.786, 0.58, 0.87],\n",
        "        [0.689, 0.44, 0.92],\n",
        "        [0.628, 0.32, 0.81]]\n",
        "    result = func(example)\n",
        "    assert len(result) == len(example), \\\n",
        "        (\"Color context representations need to represent each color \"\n",
        "         \"separately. (We assume the final color is the target.)\")\n",
        "    for i, color in enumerate(result):\n",
        "        assert all(isinstance(x, float) for x in color), \\\n",
        "            (\"All color representations should be lists of floats. \"\n",
        "             \"Color {} is {}\".format(i, color))\n",
        "        \n",
        "test_represent_color_context(represent_color_context)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kZ0ySv11natW"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_cols_train = [represent_color_context(colors) for colors in dev_rawcols_train]\n",
        "dev_cols_test = [represent_color_context(colors) for colors in dev_rawcols_test]"
      ],
      "metadata": {
        "trusted": true,
        "id": "WHSz7RX9natX"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the improved model, training tends to last for more epochs before early stopping kicks in. The following code should take about five minutes to run, although there could be some variation depending on how you implemented the tokenization and color models:"
      ],
      "metadata": {
        "id": "WxwQsuu3natX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mod = ContextualColorDescriber(dev_vocab, early_stopping=True)\n",
        "%time _ = dev_mod.fit(dev_cols_train, dev_seqs_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-OHCWkXTnatX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f357f092-ea76-45ae-faf3-b3e1d93891bb"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stopping after epoch 124. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 15.474966287612915"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 40s, sys: 834 ms, total: 4min 41s\n",
            "Wall time: 4min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### "
      ],
      "metadata": {
        "id": "Z9h8W-ESnatX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our reference implementation achieves a listener accuracy of 0.77 and a BLEU of 0.69. You may see some variation from these numbers, but you should aim to achieve listener accuracy above 0.7 and BLEU above 0.6 for full credit. Alternatively, you may achieve full credit by "
      ],
      "metadata": {
        "id": "NYHKjiVgnatX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = dev_mod.evaluate(dev_cols_test, dev_seqs_test)\n",
        "print(\"Listener accuracy (improved): {}\".format(evaluation['listener_accuracy']))\n",
        "print(\"BLEU (improved): {}\".format(evaluation['corpus_bleu']))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "gejz-EfMnatX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30769da5-5763-4bb6-f1d4-279ce32c6935"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listener accuracy (improved): 0.7463768115942029\n",
            "BLEU (improved): 0.687389369100563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD LENGTH + ALL: Listener accuracy (improved): 0.8042038583357328\n",
        "BLEU (improved): 0.6891308745806776\n",
        "\n",
        "MOST COMMON: Listener accuracy (improved): 0.7658514492753623\n",
        "BLEU (improved): 0.6640120008293773\n",
        "\n",
        "HSV DCT: Listener accuracy (improved): 0.6956521739130435\n",
        "BLEU (improved): 0.6004246663224859\n",
        "\n",
        "CMYK FFT:\n",
        "Listener accuracy (improved): 0.3845108695652174\n",
        "BLEU (improved): 0.5455344018617262\n",
        "\n",
        "CMYK:\n",
        "Listener accuracy (improved): 0.761322463768116\n",
        "BLEU (improved): 0.6449453528586643\n",
        "\n",
        "POS:\n",
        "Listener accuracy (improved): 0.7463768115942029\n",
        "BLEU (improved): 0.687389369100563\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vN8ES9cgjLZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rOkgmZkWTFRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also print out some example generations from the model:"
      ],
      "metadata": {
        "id": "UErgqxqdnatY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation[\"predicted_utterance\"]"
      ],
      "metadata": {
        "trusted": true,
        "id": "UmDuyP9AnatY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report: Further Experimentation\n",
        "\n",
        "Once you've got a working model, there are several opportunities for further analysis and experimentation with this dataset. Please consider any of the following tasks and write a one-page report detailing your experiments:\n",
        "* Conduct a thorough analysis of alternative methods for tokenization and color representation\n",
        "* Replace the argmax in the prediction code with a sampling-based inference procedure, and sample 5-10 possible candidate descriptions for each of a handful of examples. Then rank these examples based on listener accuracy. Do the rankings align with your intuitions?\n",
        "* Experiment with manually changing the color contexts to see whether or not this affects generated text. If it doesn't, can you modify the model so that it could? Provide some discussion of how you should expect specific color descriptions to change in different contexts.\n",
        "* Use the \"far,\" \"split,\" and \"close\" conditions to evaluate how well your model performs under different conditions. Can you retrain the model on the whole dataset (or a different subset) to make it perform better at the \"close\" condition?\n",
        "* *Advanced*: This assignment is based on a [bakeoff](https://github.com/cgpotts/cs224u/blob/master/hw_colors.ipynb) in the Stanford's CS224U course, taught by Chris Potts. Complete challenge #4 from the bakeoff, which involves feeding color embeddings into the decoder at each step of the inference procedure\n",
        "* *Advanced*: Run the code with Mandarin data from [Monroe, et al. (2018)](https://aclanthology.org/N18-1196.pdf)\n",
        "\n",
        "Please also state what final accuracies your system achieved. Feel free to come up with your own ideas for the report as well!"
      ],
      "metadata": {
        "id": "brhesm6SnatY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RANDOM CODE FOR EXPERIMENTS - NOT FINAL"
      ],
      "metadata": {
        "id": "RWqNHc2FjMA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"YOUR CODE HERE\"\"\"\n",
        "# BEGIN EXPERIMENTS\n",
        "def represent_color(color): #from monroe\n",
        "  color = [*colorsys.hls_to_rgb(*color)]\n",
        "  ranges = (256.0, 256.0, 256.0)\n",
        "  resolution = [10, 10, 10]\n",
        "  colors_internal = np.minimum(color, ranges - 1e-4)\n",
        "  bucket_sizes = tuple(d / r for d, r in zip(ranges, resolution))\n",
        "  bucket_dims = (colors_internal // np.array(bucket_sizes)).astype(np.int32)\n",
        "  result = (bucket_dims[..., 0] * resolution[1] * resolution[2] +\n",
        "                  bucket_dims[..., 1] * resolution[2] +\n",
        "                  bucket_dims[..., 2])\n",
        "  return result\n",
        "# END EXPERIMENTS"
      ],
      "metadata": {
        "trusted": true,
        "id": "0B1DbsvlnatY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.fftpack import fft, dct\n",
        "def represent_color(color):\n",
        "  h, s, v, k = rgb_to_cmyk(*colorsys.hls_to_rgb(*color))\n",
        "  fourier = [] #np.zeros(54)\n",
        "  for j in range(4):\n",
        "      for k in range(4):\n",
        "        for l in range(4):\n",
        "          f = np.exp(-2*np.pi*1j *(j*h + k*s + l*v))\n",
        "          f = [np.real(f), np.imag(f)] #all real, all imaginary does not work\n",
        "          fourier.extend(f)\n",
        "  return fourier\n"
      ],
      "metadata": {
        "id": "Z7AVYsofMPpI"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.fftpack import fft, dct\n",
        "def represent_color(color):\n",
        "  #color = [*colorsys.rgb_to_hsv(*colorsys.hls_to_rgb(*color))]\n",
        "  #cosine = [] #np.zeros(54)\n",
        "  return dctr(color)"
      ],
      "metadata": {
        "id": "UIEJS0m7Zyv6"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_to_cmyk(r, g, b): \n",
        "    CMYK_SCALE = 100\n",
        "\n",
        "   \n",
        "    c = 1 - r / 255\n",
        "    m = 1 - g / 255\n",
        "    y = 1 - b / 255\n",
        "\n",
        "    min = np.min(c, m, y)\n",
        "    c = (c - min)*100 / (1 - min)\n",
        "    m = (m - min)*100 / (1 - min)\n",
        "    y = (y - min)*100 / (1 - min)\n",
        "    k = min\n",
        "\n",
        "    return c,m,y,k"
      ],
      "metadata": {
        "id": "a9baZRNmSNT3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dctr(color):\n",
        "  h, s, v = colorsys.rgb_to_hsv(*colorsys.hls_to_rgb(*color))\n",
        "  cos =[]\n",
        "  for j in range(3):\n",
        "    for k in range(3):\n",
        "      for l in range(3):\n",
        "        #f = np.cos((2*h+1)*j*np.pi/2) * np.cos((2*s+1)*k*np.pi/2) * np.cos((2*v+1)*l*np.pi/2) #wrong\n",
        "        cos.append(f)\n",
        "  return cos"
      ],
      "metadata": {
        "id": "dxcaYFv1U9lc"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3qLsy0Gcdq1P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}